{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./predictor/index_to_name.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./predictor/index_to_name.json\n",
    "\n",
    "{\n",
    "    \"0\": \"NEGATIVE\",\n",
    "    \"1\": \"NEUTRAL\",\n",
    "    \"2\": \"POSITIVE\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting predictor/custom_handler.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile predictor/custom_handler.py\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.path.abspath(__file__)))\n",
    "\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "from ts.torch_handler.base_handler import BaseHandler\n",
    "from bert_model import initialize_bert_model\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class TransformersClassifierHandler(BaseHandler):\n",
    "    \"\"\"\n",
    "    A custom handler for PyTorch Serve to handle BERT-based models\n",
    "    with additional layers and `.pth`-saved state_dict.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(TransformersClassifierHandler, self).__init__()\n",
    "        self.initialized = False\n",
    "\n",
    "    def initialize(self, ctx):\n",
    "        \"\"\"\n",
    "        Initialize the model, tokenizer, and label mapping for inference.\n",
    "        \"\"\"\n",
    "        self.manifest = ctx.manifest\n",
    "\n",
    "        properties = ctx.system_properties\n",
    "        model_dir = properties.get(\"model_dir\")\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # Load the model architecture\n",
    "        num_labels = 3  # Adjust based on your dataset (e.g., Negative, Neutral, Positive)\n",
    "        self.model = initialize_bert_model(num_labels=num_labels).to(self.device)\n",
    "\n",
    "        # Load the model state_dict\n",
    "        serialized_file = self.manifest[\"model\"][\"serializedFile\"]\n",
    "        model_path = os.path.join(model_dir, serialized_file)\n",
    "        if not os.path.isfile(model_path):\n",
    "            raise RuntimeError(f\"Missing the model file: {model_path}\")\n",
    "        self.model.load_state_dict(torch.load(model_path, map_location=self.device))\n",
    "        self.model.eval()\n",
    "        logger.info(f\"Model loaded from {model_path}\")\n",
    "\n",
    "        # Load the tokenizer\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "        # Load the label mapping\n",
    "        mapping_file_path = os.path.join(model_dir, \"index_to_name.json\")\n",
    "        if os.path.isfile(mapping_file_path):\n",
    "            with open(mapping_file_path, \"r\") as f:\n",
    "                self.mapping = json.load(f)\n",
    "        else:\n",
    "            logger.warning(\"index_to_name.json not found. Using default label mapping.\")\n",
    "            self.mapping = {\"0\": \"Negative\", \"1\": \"Neutral\", \"2\": \"Positive\"}\n",
    "\n",
    "        self.initialized = True\n",
    "\n",
    "        \n",
    "\n",
    "    # def preprocess(self, data):\n",
    "    #     \"\"\"\n",
    "    #     Preprocess input data by tokenizing the text and creating input tensors.\n",
    "    #     \"\"\"\n",
    "    #     input_text = data[0].get(\"data\") or data[0].get(\"body\")\n",
    "    #     if isinstance(input_text, bytes):\n",
    "    #         input_text = input_text.decode(\"utf-8\")\n",
    "    #     logger.info(f\"Received input: {input_text}\")\n",
    "\n",
    "    #     # Tokenize the input text\n",
    "    #     inputs = self.tokenizer(\n",
    "    #         input_text,\n",
    "    #         padding=\"max_length\",\n",
    "    #         max_length=128,\n",
    "    #         truncation=True,\n",
    "    #         return_tensors=\"pt\"\n",
    "    #     )\n",
    "    #     return {\n",
    "    #         \"input_ids\": inputs[\"input_ids\"].to(self.device),\n",
    "    #         \"attention_mask\": inputs[\"attention_mask\"].to(self.device)\n",
    "    #     }\n",
    "\n",
    "    def preprocess(self, data):\n",
    "        # Ensure 'instances' key exists\n",
    "        if \"instances\" not in data:\n",
    "            raise ValueError(\"Invalid input format. Expected a JSON object with 'instances' key.\")\n",
    "        \n",
    "        # Extract instances\n",
    "        instances = data[\"instances\"]\n",
    "\n",
    "        # Process each instance\n",
    "        texts = [instance[\"text\"] for instance in instances]\n",
    "        additional_features = [\n",
    "            [instance[\"price\"], \n",
    "            float(instance[\"price_missing\"]), \n",
    "            instance[\"helpful_vote\"], \n",
    "            float(instance[\"verified_purchase\"])]\n",
    "            for instance in instances\n",
    "        ]\n",
    "\n",
    "        # Tokenize text data\n",
    "        tokenized = self.tokenizer(\n",
    "            texts, \n",
    "            padding=\"max_length\", \n",
    "            truncation=True, \n",
    "            max_length=128, \n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        return tokenized, torch.tensor(additional_features, dtype=torch.float32)\n",
    "\n",
    "    # def inference(self, inputs):\n",
    "    #     \"\"\"\n",
    "    #     Perform inference using the loaded model and processed inputs.\n",
    "    #     \"\"\"\n",
    "    #     with torch.no_grad():\n",
    "    #         outputs = self.model(\n",
    "    #             input_ids=inputs[\"input_ids\"],\n",
    "    #             attention_mask=inputs[\"attention_mask\"]\n",
    "    #         )\n",
    "    #         logits = outputs[\"logits\"]\n",
    "    #         prediction = torch.argmax(logits, dim=1).item()\n",
    "\n",
    "    #     # Map prediction to label\n",
    "    #     predicted_label = self.mapping.get(str(prediction), \"Unknown\")\n",
    "    #     logger.info(f\"Prediction: {predicted_label}\")\n",
    "    #     return [predicted_label]\n",
    "\n",
    "    def inference(self, inputs):\n",
    "        \"\"\"\n",
    "        Perform inference using the loaded model and processed inputs.\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(\n",
    "                input_ids=inputs[\"input_ids\"],\n",
    "                attention_mask=inputs[\"attention_mask\"],\n",
    "                additional_features=inputs[\"additional_features\"]\n",
    "            )\n",
    "            logits = outputs[\"logits\"]\n",
    "            prediction = torch.argmax(logits, dim=1).item()\n",
    "\n",
    "        # Map prediction to label\n",
    "        predicted_label = self.mapping.get(str(prediction), \"Unknown\")\n",
    "        return [predicted_label]\n",
    "\n",
    "\n",
    "    def postprocess(self, inference_output):\n",
    "        \"\"\"\n",
    "        Post-process the output to be returned as a JSON response.\n",
    "        \"\"\"\n",
    "        return inference_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting predictor/custom_handler.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile predictor/custom_handler.py\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.path.abspath(__file__)))\n",
    "\n",
    "import json\n",
    "import logging\n",
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "from ts.torch_handler.base_handler import BaseHandler\n",
    "from bert_model import initialize_bert_model\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class TransformersClassifierHandler(BaseHandler):\n",
    "    \"\"\"\n",
    "    A custom handler for PyTorch Serve to handle BERT-based models\n",
    "    with additional layers and `.pth`-saved state_dict.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(TransformersClassifierHandler, self).__init__()\n",
    "        self.initialized = False\n",
    "\n",
    "    def initialize(self, ctx):\n",
    "        \"\"\"\n",
    "        Initialize the model, tokenizer, and label mapping for inference.\n",
    "        \"\"\"\n",
    "        self.manifest = ctx.manifest\n",
    "        properties = ctx.system_properties\n",
    "        model_dir = properties.get(\"model_dir\")\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # Load the model architecture\n",
    "        num_labels = 3  # Adjust based on your dataset\n",
    "        self.model = initialize_bert_model(num_labels=num_labels).to(self.device)\n",
    "\n",
    "        # Load the model state_dict\n",
    "        serialized_file = self.manifest[\"model\"][\"serializedFile\"]\n",
    "        model_path = os.path.join(model_dir, serialized_file)\n",
    "        if not os.path.isfile(model_path):\n",
    "            raise RuntimeError(f\"Missing the model file: {model_path}\")\n",
    "        self.model.load_state_dict(torch.load(model_path, map_location=self.device))\n",
    "        self.model.eval()\n",
    "        logger.info(f\"Model loaded from {model_path}\")\n",
    "\n",
    "        # Load the tokenizer\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "        # Load the label mapping\n",
    "        mapping_file_path = os.path.join(model_dir, \"index_to_name.json\")\n",
    "        if os.path.isfile(mapping_file_path):\n",
    "            with open(mapping_file_path, \"r\") as f:\n",
    "                self.mapping = json.load(f)\n",
    "        else:\n",
    "            logger.warning(\"index_to_name.json not found. Using default label mapping.\")\n",
    "            self.mapping = {\"0\": \"Negative\", \"1\": \"Neutral\", \"2\": \"Positive\"}\n",
    "\n",
    "        self.initialized = True\n",
    "\n",
    "    def preprocess(self, data):\n",
    "        \"\"\"\n",
    "        Preprocessing input request by tokenizing and extracting additional features.\n",
    "        Extend with your own preprocessing steps as needed.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Log the received data\n",
    "            logger.info(f\"Received input data: {data}\")\n",
    "            logger.info(f\"Data type: {type(data)}\")\n",
    "\n",
    "            # # Handle byte inputs or TorchServe-wrapped inputs\n",
    "            # if isinstance(data, (bytes, bytearray)):\n",
    "            #     data = json.loads(data.decode(\"utf-8\"))\n",
    "            # elif isinstance(data, list):\n",
    "            #     if isinstance(data[0], (bytes, bytearray)):\n",
    "            #         data = json.loads(data[0].decode(\"utf-8\"))\n",
    "            #     else:\n",
    "            # data = data[0]\n",
    "\n",
    "            # # Ensure data contains \"instances\" key\n",
    "            # if not isinstance(data, dict):\n",
    "            #     raise ValueError(\"Invalid input format. Expected a JSON object.\")\n",
    "            # if \"instances\" not in data:\n",
    "            #     raise ValueError(\"Invalid input format. Expected a JSON object with 'instances' key.\")\n",
    "\n",
    "            # Extract instances\n",
    "            instances = data#.keys()\n",
    "            logger.info(f\"Parsed instances: {instances}\")\n",
    "            logger.info(f\"Parsed instances: {instances}\")\n",
    "\n",
    "            texts = []\n",
    "            additional_features = []\n",
    "            \n",
    "            # Extract and validate data from each instance\n",
    "            for instance in instances:\n",
    "                # if not all(key in instance for key in [\"text\", \"price\", \"price_missing\", \"helpful_vote\", \"verified_purchase\"]):\n",
    "                #     raise ValueError(f\"Invalid instance format: {instance}\")\n",
    "                \n",
    "                texts.append(instance[\"text\"])\n",
    "                additional_features.append([\n",
    "                    float(instance[\"price\"]),\n",
    "                    float(instance[\"price_missing\"]),\n",
    "                    float(instance[\"helpful_vote\"]),\n",
    "                    float(instance[\"verified_purchase\"])\n",
    "                ])\n",
    "\n",
    "            # Log extracted inputs\n",
    "            logger.info(f\"Extracted texts: {texts}\")\n",
    "            logger.info(f\"Extracted additional features: {additional_features}\")\n",
    "\n",
    "            # Tokenize text inputs\n",
    "            tokenized = self.tokenizer(\n",
    "                texts,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                max_length=128,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            logger.info(f\"Tokenized input_ids: {tokenized['input_ids']}\")\n",
    "            logger.info(f\"Tokenized attention_mask: {tokenized['attention_mask']}\")\n",
    "\n",
    "            # Return the processed inputs\n",
    "            return {\n",
    "                \"input_ids\": tokenized[\"input_ids\"].to(self.device),\n",
    "                \"attention_mask\": tokenized[\"attention_mask\"].to(self.device),\n",
    "                \"additional_features\": torch.tensor(additional_features, dtype=torch.float32).to(self.device)\n",
    "            }\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Preprocessing failed: {e}\")\n",
    "            raise ValueError(f\"Error during preprocessing: {e}\")\n",
    "\n",
    "    def inference(self, inputs):\n",
    "        \"\"\"\n",
    "        Perform inference using the loaded model and processed inputs.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logger.info(f\"Inference inputs: {inputs}\")\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(\n",
    "                    input_ids=inputs[\"input_ids\"],\n",
    "                    attention_mask=inputs[\"attention_mask\"],\n",
    "                    additional_features=inputs[\"additional_features\"]\n",
    "                )\n",
    "                logits = outputs[\"logits\"]\n",
    "                predictions = torch.argmax(logits, dim=1).tolist()\n",
    "\n",
    "            logger.info(f\"Inference outputs (logits): {logits}\")\n",
    "            logger.info(f\"Predicted labels: {predictions}\")\n",
    "            logger.info(self.mapping,[(self.mapping.get(str(pred), \"Unknown\"),pred) for pred in predictions])\n",
    "            return [self.mapping.get(str(pred), \"Unknown\") for pred in predictions]\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Inference failed: {e}\")\n",
    "            raise ValueError(f\"Error during inference: {e}\")\n",
    "\n",
    "    def postprocess(self, inference_output):\n",
    "        \"\"\"\n",
    "        Post-processes the model output for returning to the client.\n",
    "        \"\"\"\n",
    "        logger.info(f\"Postprocessing output: {inference_output}\")\n",
    "        # return {\"predictions\": inference_output}\n",
    "        return inference_output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash -s $APP_NAME\n",
    "\n",
    "# APP_NAME=$1\n",
    "\n",
    "# cat << EOF > ./predictor/Dockerfile\n",
    "\n",
    "# FROM pytorch/torchserve:latest-cpu\n",
    "\n",
    "# # Install dependencies\n",
    "# RUN python3 -m pip install --upgrade pip\n",
    "# RUN pip3 install transformers\n",
    "\n",
    "# # Switch to the model-server user\n",
    "# USER model-server\n",
    "\n",
    "# # Set the model directory path\n",
    "# WORKDIR /home/model-server/\n",
    "\n",
    "# # Copy model artifacts, custom handler, and utilities\n",
    "# COPY ./bert-sent-model /home/model-server/bert-sent-model/\n",
    "# COPY ./custom_handler.py /home/model-server/custom_handler.py\n",
    "# COPY ./data_loader.py /home/model-server/data_loader.py\n",
    "# COPY ./bert_model.py /home/model-server/bert_model.py\n",
    "\n",
    "# COPY ./utils /home/model-server/utils/\n",
    "# COPY ./index_to_name.json /home/model-server/\n",
    "\n",
    "# # Verify the contents of the server directory\n",
    "# RUN ls -l /home/model-server\n",
    "\n",
    "# # Switch to root user for configuration\n",
    "# USER root\n",
    "\n",
    "# # Create TorchServe configuration file\n",
    "# RUN printf \"\\nservice_envelope=json\" >> /home/model-server/config.properties\n",
    "# RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home/model-server/config.properties\n",
    "# RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /home/model-server/config.properties\n",
    "# RUN printf \"\\ndisable_token_authorization=true\" >> /home/model-server/config.properties\n",
    "\n",
    "# # Change permissions for the model-server user\n",
    "# RUN chown -R model-server:model-server /home/model-server\n",
    "\n",
    "# # Switch back to the model-server user\n",
    "# USER model-server\n",
    "\n",
    "# # Expose health and prediction listener ports from the image\n",
    "# EXPOSE 7080\n",
    "# EXPOSE 7081\n",
    "\n",
    "# # Create the TorchServe model archive\n",
    "# RUN torch-model-archiver -f \\\n",
    "#     --model-name bert_classifier \\\n",
    "#     --version 1.0 \\\n",
    "#     --serialized-file /home/model-server/bert-sent-model/final_model.pth \\\n",
    "#     --handler /home/model-server/custom_handler.py \\\n",
    "#     --extra-files \"/home/model-server/bert_model.py,/home/model-server/data_loader.py,/home/model-server/utils/roberta_model.py,/home/model-server/index_to_name.json\" \\\n",
    "#     --export-path /home/model-server/model-store\n",
    "\n",
    "# # Start TorchServe\n",
    "# CMD [\"torchserve\", \\\n",
    "#      \"--start\", \\\n",
    "#      \"--ts-config=/home/model-server/config.properties\", \\\n",
    "#      \"--models\", \\\n",
    "#      \"bert_classifier=bert_classifier.mar\", \\\n",
    "#      \"--model-store\", \\\n",
    "#      \"/home/model-server/model-store\"]\n",
    "# EOF\n",
    "\n",
    "# echo \"Writing ./predictor/Dockerfile\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"amazonreviewssentimentanalysis\"  # <---CHANGE THIS TO YOUR PROJECT\n",
    "APP_NAME = \"review_sentiment_bert_model\"\n",
    "BUCKET_NAME = \"gs://arsa_model_deployment_uscentral\"\n",
    "REGION = 'us-central1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./predictor/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%bash -s $APP_NAME\n",
    "\n",
    "APP_NAME=$1\n",
    "\n",
    "cat << EOF > ./predictor/Dockerfile\n",
    "\n",
    "FROM pytorch/torchserve:latest-cpu\n",
    "\n",
    "# Install dependencies\n",
    "RUN python3 -m pip install --upgrade pip\n",
    "RUN pip3 install transformers\n",
    "\n",
    "# Switch to the model-server user\n",
    "USER model-server\n",
    "\n",
    "# Set the model directory path\n",
    "WORKDIR /home/model-server/\n",
    "\n",
    "# Copy model artifacts, custom handler, and utilities\n",
    "COPY ./bert-sent-model /home/model-server/bert-sent-model/\n",
    "COPY ./custom_handler.py /home/model-server/custom_handler.py\n",
    "COPY ./data_loader.py /home/model-server/data_loader.py\n",
    "COPY ./bert_model.py /home/model-server/bert_model.py\n",
    "COPY ./utils /home/model-server/utils/\n",
    "COPY ./index_to_name.json /home/model-server/\n",
    "\n",
    "# Verify the contents of the server directory\n",
    "RUN ls -l /home/model-server\n",
    "\n",
    "# Switch to root user for configuration\n",
    "USER root\n",
    "\n",
    "# Create TorchServe configuration file\n",
    "RUN printf \"\\nservice_envelope=json\" >> /home/model-server/config.properties\n",
    "RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home/model-server/config.properties\n",
    "RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /home/model-server/config.properties\n",
    "RUN printf \"\\ndisable_token_authorization=true\" >> /home/model-server/config.properties\n",
    "\n",
    "# Change permissions for the model-server user\n",
    "RUN chown -R model-server:model-server /home/model-server\n",
    "\n",
    "# Switch back to the model-server user\n",
    "USER model-server\n",
    "\n",
    "# Expose health and prediction listener ports from the image\n",
    "EXPOSE 7080\n",
    "EXPOSE 7081\n",
    "\n",
    "# Create the TorchServe model archive\n",
    "RUN torch-model-archiver -f \\\n",
    "    --model-name=$APP_NAME \\\n",
    "    --version 1.0 \\\n",
    "    --serialized-file /home/model-server/bert-sent-model/final_model.pth \\\n",
    "    --handler /home/model-server/custom_handler.py \\\n",
    "    --extra-files \"/home/model-server/bert_model.py,/home/model-server/data_loader.py,/home/model-server/utils/roberta_model.py,/home/model-server/index_to_name.json\" \\\n",
    "    --export-path /home/model-server/model-store\n",
    "\n",
    "# Start TorchServe\n",
    "CMD [\"torchserve\", \\\n",
    "     \"--start\", \\\n",
    "     \"--ts-config=/home/model-server/config.properties\", \\\n",
    "     \"--models\", \\\n",
    "     \"$APP_NAME=$APP_NAME.mar\", \\\n",
    "     \"--model-store\", \\\n",
    "     \"/home/model-server/model-store\"]\n",
    "EOF\n",
    "\n",
    "echo \"Writing ./predictor/Dockerfile\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUSTOM_PREDICTOR_IMAGE_URI = gcr.io/amazonreviewssentimentanalysis/pytorch_predict_review_sentiment_bert_model\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "CUSTOM_PREDICTOR_IMAGE_URI = f\"gcr.io/{PROJECT_ID}/pytorch_predict_{APP_NAME}\"\n",
    "print(f\"CUSTOM_PREDICTOR_IMAGE_URI = {CUSTOM_PREDICTOR_IMAGE_URI}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Building 0.0s (0/1)                                    docker:desktop-linux\n",
      "\u001b[?25h\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.2s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.20kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.2s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.3s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.20kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.3s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.5s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.20kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.5s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.6s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.20kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.6s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.8s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.20kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.8s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.9s (2/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.20kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.1s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  0.2s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.3s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  0.3s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.4s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  0.5s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.6s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  0.6s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.7s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  0.8s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.9s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  0.9s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.0s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  1.1s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.2s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  1.2s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.3s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  1.4s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.5s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  1.5s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.6s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  1.7s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.8s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  1.8s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.9s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  2.0s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 3.1s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  2.1s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 3.2s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  2.3s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 3.4s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  2.4s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 3.5s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  2.6s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 3.7s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  2.7s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 3.8s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  2.9s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 4.0s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  3.0s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 4.1s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  3.2s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 4.3s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  3.3s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 4.4s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  3.5s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 4.6s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  3.6s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 4.7s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  3.8s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 4.9s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  3.9s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 5.0s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  4.1s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 5.2s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  4.2s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 5.3s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  4.4s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 5.5s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  4.5s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 5.6s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  4.7s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 5.8s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  4.8s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 5.9s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  5.0s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 6.1s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  5.1s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 6.2s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  5.3s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 6.4s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  5.4s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 6.5s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  5.6s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 6.7s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  5.7s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 6.8s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  5.9s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 7.0s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  6.0s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 7.1s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  6.2s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 7.3s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  6.3s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 7.4s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  6.5s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 7.6s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  6.6s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 7.7s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  6.8s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 7.9s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  6.9s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 8.0s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  7.1s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 8.2s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  7.2s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 8.3s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  7.4s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 8.5s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  7.5s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 8.6s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  7.7s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 8.8s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  7.8s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 8.9s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  8.0s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 9.1s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  8.1s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 9.2s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  8.3s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 9.4s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  8.4s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 9.5s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  8.6s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 9.7s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  8.7s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 9.8s (20/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  8.9s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 10.0s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  9.0s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 10.1s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  9.2s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 10.3s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  9.3s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 10.4s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  9.5s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 10.6s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  9.6s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 10.7s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  9.8s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 10.9s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  9.9s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 11.0s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  10.1s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 11.2s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  10.2s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 11.3s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  10.4s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 11.5s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  10.5s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 11.6s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  10.7s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 11.8s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  10.8s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 11.9s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  11.0s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 12.1s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  11.1s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 12.2s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  11.3s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 12.4s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  11.4s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 12.5s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  11.6s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 12.7s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  11.7s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 12.8s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  11.9s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 13.0s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  12.0s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 13.1s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  12.2s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 13.3s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  12.3s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 13.4s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  12.5s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 13.6s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  12.6s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 13.7s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  12.8s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 13.9s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  12.9s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 14.0s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  13.1s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 14.2s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  13.2s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 14.3s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  13.4s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 14.5s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  13.5s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 14.6s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  13.7s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 14.8s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  13.8s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 14.9s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  14.0s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 15.1s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  14.1s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 15.2s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  14.3s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 15.4s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  14.4s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 15.5s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  14.6s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 15.6s (21/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m\u001b[34m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  14.7s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 15.8s (21/22)                                 docker:desktop-linux\n",
      "\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m\u001b[34m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  14.7s\n",
      "\u001b[0m => exporting to image                                                     0.2s\n",
      " => => exporting layers                                                    0.2s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 15.9s (21/22)                                 docker:desktop-linux\n",
      "\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m\u001b[34m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  14.7s\n",
      "\u001b[0m => exporting to image                                                     0.3s\n",
      " => => exporting layers                                                    0.3s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 16.1s (21/22)                                 docker:desktop-linux\n",
      "\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m\u001b[34m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  14.7s\n",
      "\u001b[0m => exporting to image                                                     0.5s\n",
      " => => exporting layers                                                    0.5s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 16.2s (21/22)                                 docker:desktop-linux\n",
      "\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m\u001b[34m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  14.7s\n",
      "\u001b[0m => exporting to image                                                     0.6s\n",
      "\u001b[34m => => exporting layers                                                    0.5s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 16.2s (22/22) FINISHED                        docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.20kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 8.10kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./custom_handler.py /home/model-server/custom_han  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/17] COPY ./data_loader.py /home/model-server/data_loader.p  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/17] COPY ./bert_model.py /home/model-server/bert_model.py   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/17] COPY ./utils /home/model-server/utils/                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [10/17] COPY ./index_to_name.json /home/model-server/           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [11/17] RUN ls -l /home/model-server                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-se  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\"   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /ho  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [16/17] RUN chown -R model-server:model-server /home/model-ser  0.0s\n",
      "\u001b[0m\u001b[34m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  14.7s\n",
      "\u001b[0m\u001b[34m => exporting to image                                                     0.6s\n",
      "\u001b[0m\u001b[34m => => exporting layers                                                    0.5s\n",
      "\u001b[0m\u001b[34m => => writing image sha256:c67acd0fa79b0d6c0f176ddd75ed1918a99162cb0eab2  0.0s\n",
      "\u001b[0m\u001b[34m => => naming to gcr.io/amazonreviewssentimentanalysis/pytorch_predict_re  0.0s\n",
      "\u001b[0m\u001b[?25h\n",
      "View build details: \u001b]8;;docker-desktop://dashboard/build/desktop-linux/desktop-linux/hn5ry1asxy88w36eog7dvy3br\u001b\\docker-desktop://dashboard/build/desktop-linux/desktop-linux/hn5ry1asxy88w36eog7dvy3br\u001b]8;;\u001b\\\n",
      "\u001b[1m\n",
      "What's next:\u001b[0m\n",
      "    View a summary of image vulnerabilities and recommendations → \u001b[36mdocker scout quickview \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!docker build \\\n",
    "  --tag=$CUSTOM_PREDICTOR_IMAGE_URI \\\n",
    "  ./predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_bert_classifier\n",
      "887b83bfcb8000ae61bf0ebb618928b513524ec51051044242b4de8925008e18\n"
     ]
    }
   ],
   "source": [
    "!docker stop local_bert_classifier\n",
    "!docker run -t -d --rm -p 7080:7080 --name=local_bert_classifier $CUSTOM_PREDICTOR_IMAGE_URI\n",
    "!sleep 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status\": \"Healthy\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!curl http://localhost:7080/ping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !curl -X POST \\\n",
    "#      -H \"Content-Type: application/json\" \\\n",
    "#      -d '{\n",
    "#          \"instances\": [\n",
    "#              {\n",
    "#                  \"text\": \"The product was excellent and exceeded my expectations.\",\n",
    "#                  \"title\": \"Excellent Quality\",\n",
    "#                  \"price\": 49.99,\n",
    "#                  \"price_missing\": false,\n",
    "#                  \"helpful_vote\": 15,\n",
    "#                  \"verified_purchase\": true\n",
    "#              }\n",
    "#          ]\n",
    "#         }' \\\n",
    "#      http://localhost:7080/predictions/bert_classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./predictor/instances.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./predictor/instances.json\n",
    "\n",
    "{\n",
    "    \"instances\": [\n",
    "        {\n",
    "            \"text\": \"The product was excellent and exceeded my expectations.\",\n",
    "            \"title\": \"Excellent Quality\",\n",
    "            \"price\": 49.99,\n",
    "            \"price_missing\": false,\n",
    "            \"helpful_vote\": 15,\n",
    "            \"verified_purchase\": true\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"The product was excellent and exceeded my expectations.\",\n",
    "            \"title\": \"Excellent Quality\",\n",
    "            \"price\": 49.99,\n",
    "            \"price_missing\": false,\n",
    "            \"helpful_vote\": 15,\n",
    "            \"verified_purchase\": true\n",
    "        }\n",
    "\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = [{'text': 'The product was XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXmy expectations.', 'title': 'Excellent Quality', 'price': 49.99, 'price_missing': False, 'helpful_vote': 15, 'verified_purchase': True}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The product was XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXmy expectations.\n"
     ]
    }
   ],
   "source": [
    "texts = []\n",
    "additional_features = []\n",
    "\n",
    "# Extract and validate data from each instance\n",
    "for instance in instances:\n",
    "    # if not all(key in instance for key in [\"text\", \"price\", \"price_missing\", \"helpful_vote\", \"verified_purchase\"]):\n",
    "    #     raise ValueError(f\"Invalid instance format: {instance}\")\n",
    "    print(instance[\"text\"])\n",
    "    texts.append(instance[\"text\"])\n",
    "    additional_features.append([\n",
    "        float(instance[\"price\"]),\n",
    "        float(instance[\"price_missing\"]),\n",
    "        float(instance[\"helpful_vote\"]),\n",
    "        float(instance[\"verified_purchase\"])\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[49.99, 0.0, 15.0, 1.0]],\n",
       " ['The product was XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXmy expectations.'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "additional_features, texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Test with docker service running:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saves a instances.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./predictor/instances.json\n",
    "\n",
    "{\n",
    "    \"instances\": [\n",
    "        {\n",
    "            \"text\": \"The product was excellent and exceeded my expectations.\",\n",
    "            \"title\": \"Excellent Quality\",\n",
    "            \"price\": 49.99,\n",
    "            \"price_missing\": false,\n",
    "            \"helpful_vote\": 15,\n",
    "            \"verified_purchase\": true\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"The product was excellent and exceeded my expectations.\",\n",
    "            \"title\": \"Excellent Quality\",\n",
    "            \"price\": 49.99,\n",
    "            \"price_missing\": false,\n",
    "            \"helpful_vote\": 15,\n",
    "            \"verified_purchase\": true\n",
    "        }\n",
    "\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docker pull that image\n",
    "# docker build it with a tag once service up: test health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helth check\n",
    "!curl http://localhost:7080/ping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"predictions\": [\"POSITIVE\", \"POSITIVE\"]}"
     ]
    }
   ],
   "source": [
    "#submit 2 instances\n",
    "!curl -X POST \\\n",
    "    -H \"Content-Type: application/json\" \\\n",
    "    -d @./predictor/instances.json \\\n",
    "    http://localhost:7080/predictions/{MODEL_NAME}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON is valid\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "data = '''{\n",
    "    \"instances\": [\n",
    "        {\n",
    "            \"text\": \"The product was excellent and exceeded my expectations.\",\n",
    "            \"title\": \"Excellent Quality\",\n",
    "            \"price\": 49.99,\n",
    "            \"price_missing\": false,\n",
    "            \"helpful_vote\": 15,\n",
    "            \"verified_purchase\": true\n",
    "        }\n",
    "    ]\n",
    "}'''\n",
    "\n",
    "try:\n",
    "    json.loads(data)\n",
    "    print(\"JSON is valid\")\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"JSON is invalid: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gcr.io/amazonreviewssentimentanalysis/pytorch_predict_review_sentiment_bert_model'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CUSTOM_PREDICTOR_IMAGE_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default tag: latest\n",
      "The push refers to repository [gcr.io/amazonreviewssentimentanalysis/pytorch_predict_review_sentiment_bert_model]\n",
      "\n",
      "\u001b[1B1f14237c: Preparing \n",
      "\u001b[1B53a2e40c: Preparing \n",
      "\u001b[1B5ebbaa33: Preparing \n",
      "\u001b[1B7fd5917d: Preparing \n",
      "\u001b[1B5889c774: Preparing \n",
      "\u001b[1Bb34d3786: Preparing \n",
      "\u001b[1Bbf18a086: Preparing \n",
      "\u001b[1B2781bbe2: Preparing \n",
      "\u001b[1B72a20011: Preparing \n",
      "\u001b[1Be36f0de6: Preparing \n",
      "\u001b[1Bce061fd9: Preparing \n",
      "\u001b[1Bbf25fa3f: Preparing \n",
      "\u001b[7Bbf18a086: Preparing \n",
      "\u001b[1Bc73cb705: Preparing \n",
      "\u001b[9Bbf18a086: Preparing \n",
      "\u001b[1B1bba1191: Preparing \n",
      "\u001b[1Bad708752: Preparing \n",
      "\u001b[1B8883823f: Preparing \n",
      "\u001b[1Bb40df9dc: Preparing \n",
      "\u001b[1Ba2533c0c: Preparing \n",
      "\u001b[1B69d81cd9: Preparing \n",
      "\u001b[1Ba9d1cad1: Preparing \n",
      "\u001b[23Bf14237c: Pushed   405.6MB/405.6MB1A\u001b[2K\u001b[23A\u001b[2K\u001b[18A\u001b[2K\u001b[15A\u001b[2K\u001b[17A\u001b[2K\u001b[16A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[11A\u001b[2K\u001b[12A\u001b[2K\u001b[13A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[10A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[23A\u001b[2K\u001b[6A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[1A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2K\u001b[23A\u001b[2Klatest: digest: sha256:95deaa738ce1c7457ff2f99ee9ae65efc085b8bac9b90df74428a3efbef82e2c size: 5539\n"
     ]
    }
   ],
   "source": [
    "!docker push $CUSTOM_PREDICTOR_IMAGE_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "APP_NAME = \"review_sentiment_bert_model\"\n",
    "BUCKET_NAME = \"gs://arsa_model_deployment_uscentral\"\n",
    "REGION = 'us-central1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predict_custom_trained_model_sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpredict_custom_trained_model_sample\u001b[49m(\n\u001b[1;32m      2\u001b[0m     project\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m661148801406\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     endpoint_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m5854830148674650112\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     location\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mus-central1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     instances\u001b[38;5;241m=\u001b[39m{ \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstance_key_1\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m,}\n\u001b[1;32m      6\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predict_custom_trained_model_sample' is not defined"
     ]
    }
   ],
   "source": [
    "predict_custom_trained_model_sample(\n",
    "    project=\"661148801406\",\n",
    "    endpoint_id=\"5854830148674650112\",\n",
    "    location=\"us-central1\",\n",
    "    instances={ \"instance_key_1\": \"value\",}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import google.auth\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform import gapic as aip\n",
    "from google.cloud.aiplatform import hyperparameter_tuning as hpt\n",
    "from google.protobuf.json_format import MessageToDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, staging_bucket=BUCKET_NAME)#, credentials=\"/home/hrs/Documents/GCP_keys/key.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = 1\n",
    "model_display_name = f\"{APP_NAME}-v{VERSION}\"\n",
    "model_description = \"PyTorch serve deploymend model for amazon reviews classification\"\n",
    "\n",
    "MODEL_NAME = APP_NAME\n",
    "health_route = \"/ping\"\n",
    "predict_route = f\"/predictions/{MODEL_NAME}\"\n",
    "serving_container_ports = [7080]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "Create Model backing LRO: projects/661148801406/locations/us-central1/models/67858559131451392/operations/7923936656476864512\n",
      "Model created. Resource name: projects/661148801406/locations/us-central1/models/67858559131451392@1\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/661148801406/locations/us-central1/models/67858559131451392@1')\n",
      "review_sentiment_bert_model-v1\n",
      "projects/661148801406/locations/us-central1/models/67858559131451392\n"
     ]
    }
   ],
   "source": [
    "model = aiplatform.Model.upload(\n",
    "    display_name=model_display_name,\n",
    "    description=model_description,\n",
    "    serving_container_image_uri=CUSTOM_PREDICTOR_IMAGE_URI,\n",
    "    serving_container_predict_route=predict_route,\n",
    "    serving_container_health_route=health_route,\n",
    "    serving_container_ports=serving_container_ports,\n",
    ")\n",
    "\n",
    "model.wait()\n",
    "\n",
    "print(model.display_name)\n",
    "print(model.resource_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Create an Endpoint for Model with Custom Container**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Endpoint\n",
      "Create Endpoint backing LRO: projects/661148801406/locations/us-central1/endpoints/3348154743577903104/operations/3906725788862382080\n",
      "Endpoint created. Resource name: projects/661148801406/locations/us-central1/endpoints/3348154743577903104\n",
      "To use this Endpoint in another session:\n",
      "endpoint = aiplatform.Endpoint('projects/661148801406/locations/us-central1/endpoints/3348154743577903104')\n"
     ]
    }
   ],
   "source": [
    "endpoint_display_name = f\"{APP_NAME}-endpoint\"\n",
    "endpoint = aiplatform.Endpoint.create(display_name=endpoint_display_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Deploy the Model to Endpoint**\n",
    "\n",
    "Deploying a model associates physical resources with the model so it can serve online predictions with low latency. \n",
    "\n",
    "**NOTE:** This step takes few minutes to deploy the resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying model to Endpoint : projects/661148801406/locations/us-central1/endpoints/3348154743577903104\n",
      "Deploy Endpoint model backing LRO: projects/661148801406/locations/us-central1/endpoints/3348154743577903104/operations/6087593908416544768\n",
      "Endpoint model deployed. Resource name: projects/661148801406/locations/us-central1/endpoints/3348154743577903104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.models.Endpoint object at 0x72250de0f5b0> \n",
       "resource name: projects/661148801406/locations/us-central1/endpoints/3348154743577903104"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic_percentage = 100\n",
    "machine_type = \"n1-standard-4\"\n",
    "deployed_model_display_name = model_display_name\n",
    "min_replica_count = 1\n",
    "max_replica_count = 3\n",
    "sync = True\n",
    "\n",
    "model.deploy(\n",
    "    endpoint=endpoint,\n",
    "    deployed_model_display_name=deployed_model_display_name,\n",
    "    machine_type=machine_type,\n",
    "    traffic_percentage=traffic_percentage,\n",
    "    sync=sync,  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"projects/661148801406/locations/us-central1/endpoints/5854830148674650112\"\n",
      "display_name: \"review_sentiment_bert_model-endpoint\"\n",
      "deployed_models {\n",
      "  id: \"8619930368717357056\"\n",
      "  model: \"projects/661148801406/locations/us-central1/models/9036777217039794176\"\n",
      "  display_name: \"review_sentiment_bert_model-v2\"\n",
      "  create_time {\n",
      "    seconds: 1732728972\n",
      "    nanos: 625510000\n",
      "  }\n",
      "  dedicated_resources {\n",
      "    machine_spec {\n",
      "      machine_type: \"n1-standard-4\"\n",
      "    }\n",
      "    min_replica_count: 1\n",
      "    max_replica_count: 1\n",
      "  }\n",
      "  model_version_id: \"1\"\n",
      "}\n",
      "traffic_split {\n",
      "  key: \"8619930368717357056\"\n",
      "  value: 100\n",
      "}\n",
      "etag: \"AMEw9yPi2QVzKqcViZcjjjWWoUIddHHjXR_x8rugG9ZHG86HEjdZ-TB5uK79sG9jJh7c\"\n",
      "create_time {\n",
      "  seconds: 1732728966\n",
      "  nanos: 559808000\n",
      "}\n",
      "update_time {\n",
      "  seconds: 1732729943\n",
      "  nanos: 579557000\n",
      "}\n",
      "\n",
      "name: \"projects/661148801406/locations/us-central1/models/9036777217039794176\"\n",
      "display_name: \"review_sentiment_bert_model-v2\"\n",
      "description: \"PyTorch serve deploymend model for amazon reviews classification\"\n",
      "predict_schemata {\n",
      "}\n",
      "metadata {\n",
      "}\n",
      "container_spec {\n",
      "  image_uri: \"gcr.io/amazonreviewssentimentanalysis/bert_model\"\n",
      "  ports {\n",
      "    container_port: 7080\n",
      "  }\n",
      "  predict_route: \"/predictions/review_sentiment_bert_model\"\n",
      "  health_route: \"/ping\"\n",
      "}\n",
      "supported_deployment_resources_types: DEDICATED_RESOURCES\n",
      "supported_input_storage_formats: \"jsonl\"\n",
      "supported_input_storage_formats: \"bigquery\"\n",
      "supported_input_storage_formats: \"csv\"\n",
      "supported_input_storage_formats: \"tf-record\"\n",
      "supported_input_storage_formats: \"tf-record-gzip\"\n",
      "supported_input_storage_formats: \"file-list\"\n",
      "supported_output_storage_formats: \"jsonl\"\n",
      "supported_output_storage_formats: \"bigquery\"\n",
      "create_time {\n",
      "  seconds: 1732728695\n",
      "  nanos: 580246000\n",
      "}\n",
      "update_time {\n",
      "  seconds: 1732728901\n",
      "  nanos: 287450000\n",
      "}\n",
      "deployed_models {\n",
      "  endpoint: \"projects/661148801406/locations/us-central1/endpoints/5854830148674650112\"\n",
      "  deployed_model_id: \"8619930368717357056\"\n",
      "}\n",
      "etag: \"AMEw9yMpGr39F955goxskAK8lQOBp-flYCYTu2t1NORTKk8KmgxKYSMyOlVzvm-eFv2R\"\n",
      "supported_export_formats {\n",
      "  id: \"custom-trained\"\n",
      "  exportable_contents: IMAGE\n",
      "}\n",
      "version_id: \"1\"\n",
      "version_aliases: \"default\"\n",
      "version_create_time {\n",
      "  seconds: 1732728695\n",
      "  nanos: 580246000\n",
      "}\n",
      "version_update_time {\n",
      "  seconds: 1732728901\n",
      "  nanos: 287450000\n",
      "}\n",
      "model_source_info {\n",
      "  source_type: CUSTOM\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "endpoint = aiplatform.Endpoint(\n",
    "    endpoint_name=\"projects/661148801406/locations/us-central1/endpoints/5854830148674650112\"\n",
    ")\n",
    "print(endpoint.gca_resource)\n",
    "model = aiplatform.Model(\n",
    "    model_name=\"projects/661148801406/locations/us-central1/models/9036777217039794176\"\n",
    ")\n",
    "print(model.gca_resource)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Invoking the Endpoint with deployed Model using Vertex AI SDK to make predictions**\n",
    "##### **Get the Endpoint id**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint display name = review_sentiment_bert_model-endpoint resource id =projects/661148801406/locations/us-central1/endpoints/3348154743577903104 \n"
     ]
    }
   ],
   "source": [
    "endpoint_display_name = f\"{APP_NAME}-endpoint\"\n",
    "filter = f'display_name=\"{endpoint_display_name}\"'\n",
    "\n",
    "for endpoint_info in aiplatform.Endpoint.list(filter=filter):\n",
    "    print(\n",
    "        f\"Endpoint display name = {endpoint_info.display_name} resource id ={endpoint_info.resource_name} \"\n",
    "    )\n",
    "\n",
    "endpoint = aiplatform.Endpoint(endpoint_info.resource_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/661148801406/locations/us-central1/endpoints/3348154743577903104'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint_info.resource_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[id: \"2997186233945292800\"\n",
       " model: \"projects/661148801406/locations/us-central1/models/67858559131451392\"\n",
       " display_name: \"review_sentiment_bert_model-v1\"\n",
       " create_time {\n",
       "   seconds: 1732735180\n",
       "   nanos: 325253000\n",
       " }\n",
       " dedicated_resources {\n",
       "   machine_spec {\n",
       "     machine_type: \"n1-standard-4\"\n",
       "   }\n",
       "   min_replica_count: 1\n",
       "   max_replica_count: 1\n",
       " }\n",
       " model_version_id: \"1\"]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check endpoints for this model\n",
    "model_id = '6757955805590323200'\n",
    "endpoints = aiplatform.Endpoint.list()\n",
    "for endpoint in endpoints:\n",
    "    deployed_models = endpoint.gca_resource.deployed_models\n",
    "    for deployed_model in deployed_models:\n",
    "        if model_id in deployed_model.model:\n",
    "            print(f\"Model {model_id} is deployed to endpoint {endpoint.display_name} with ID {endpoint.resource_name}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFound",
     "evalue": "404 Endpoint `projects/661148801406/locations/us-central1/endpoints/4555119443713196032` not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/vertex_ai/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:65\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/anaconda3/envs/vertex_ai/lib/python3.10/site-packages/grpc/_channel.py:1181\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1175\u001b[0m (\n\u001b[1;32m   1176\u001b[0m     state,\n\u001b[1;32m   1177\u001b[0m     call,\n\u001b[1;32m   1178\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking(\n\u001b[1;32m   1179\u001b[0m     request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[1;32m   1180\u001b[0m )\n\u001b[0;32m-> 1181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_end_unary_response_blocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/vertex_ai/lib/python3.10/site-packages/grpc/_channel.py:1006\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1006\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.NOT_FOUND\n\tdetails = \"Endpoint `projects/661148801406/locations/us-central1/endpoints/4555119443713196032` not found.\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv6:%5B2607:f8b0:4006:820::200a%5D:443 {created_time:\"2024-11-27T12:52:53.316791328-05:00\", grpc_status:5, grpc_message:\"Endpoint `projects/661148801406/locations/us-central1/endpoints/4555119443713196032` not found.\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNotFound\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m formatted_input \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstances\u001b[39m\u001b[38;5;124m\"\u001b[39m: instances}\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Perform prediction\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstances\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatted_input\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minstances\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Print the prediction results\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrediction Response:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/vertex_ai/lib/python3.10/site-packages/google/cloud/aiplatform/models.py:2341\u001b[0m, in \u001b[0;36mEndpoint.predict\u001b[0;34m(self, instances, parameters, timeout, use_raw_predict, use_dedicated_endpoint)\u001b[0m\n\u001b[1;32m   2332\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Prediction(\n\u001b[1;32m   2333\u001b[0m         predictions\u001b[38;5;241m=\u001b[39mprediction_response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredictions\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   2334\u001b[0m         metadata\u001b[38;5;241m=\u001b[39mprediction_response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2337\u001b[0m         model_version_id\u001b[38;5;241m=\u001b[39mprediction_response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodelVersionId\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   2338\u001b[0m     )\n\u001b[1;32m   2340\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2341\u001b[0m     prediction_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prediction_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2342\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gca_resource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2343\u001b[0m \u001b[43m        \u001b[49m\u001b[43minstances\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minstances\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2346\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2347\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m prediction_response\u001b[38;5;241m.\u001b[39m_pb\u001b[38;5;241m.\u001b[39mmetadata:\n\u001b[1;32m   2348\u001b[0m         metadata \u001b[38;5;241m=\u001b[39m json_format\u001b[38;5;241m.\u001b[39mMessageToDict(prediction_response\u001b[38;5;241m.\u001b[39m_pb\u001b[38;5;241m.\u001b[39mmetadata)\n",
      "File \u001b[0;32m~/anaconda3/envs/vertex_ai/lib/python3.10/site-packages/google/cloud/aiplatform_v1/services/prediction_service/client.py:853\u001b[0m, in \u001b[0;36mPredictionServiceClient.predict\u001b[0;34m(self, request, endpoint, instances, parameters, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    850\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m    852\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 853\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/anaconda3/envs/vertex_ai/lib/python3.10/site-packages/google/api_core/gapic_v1/method.py:113\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, *args, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m     metadata\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata)\n\u001b[1;32m    111\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m metadata\n\u001b[0;32m--> 113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/vertex_ai/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:67\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 67\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mNotFound\u001b[0m: 404 Endpoint `projects/661148801406/locations/us-central1/endpoints/4555119443713196032` not found."
     ]
    }
   ],
   "source": [
    "# Define the endpoint resource name\n",
    "endpoint_name = \"projects/661148801406/locations/us-central1/endpoints/4555119443713196032\"\n",
    "\n",
    "# Create the endpoint object\n",
    "endpoint = aiplatform.Endpoint(endpoint_name=endpoint_name)\n",
    "\n",
    "# Prepare the input data\n",
    "instances = [\n",
    "    {\n",
    "        \"text\": \"The product was excellent and exceeded my expectations.\",\n",
    "        \"title\": \"Excellent Quality\",\n",
    "        \"price\": 49.99,\n",
    "        \"price_missing\": False,\n",
    "        \"helpful_vote\": 15,\n",
    "        \"verified_purchase\": True,\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"The product was bad and sucked to live my expectations.\",\n",
    "        \"title\": \"Bad Quality\",\n",
    "        \"price\": 19.99,\n",
    "        \"price_missing\": False,\n",
    "        \"helpful_vote\": 5,\n",
    "        \"verified_purchase\": False,\n",
    "    },\n",
    "]\n",
    "\n",
    "formatted_input = {\"instances\": instances}\n",
    "\n",
    "# Perform prediction\n",
    "response = endpoint.predict(instances=formatted_input[\"instances\"])\n",
    "\n",
    "# Print the prediction results\n",
    "print(\"Prediction Response:\")\n",
    "print(json.dumps(response.predictions, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Input instance: \n",
      "\t{'text': 'The product was excellent and exceeded my expectations.', 'title': 'Excellent Quality', 'price': 49.99, 'price_missing': False, 'helpful_vote': 15, 'verified_purchase': True}\n",
      "\n",
      "Formatted input JSON: \n",
      "{\n",
      "    \"instances\": [\n",
      "        {\n",
      "            \"text\": \"The product was excellent and exceeded my expectations.\",\n",
      "            \"title\": \"Excellent Quality\",\n",
      "            \"price\": 49.99,\n",
      "            \"price_missing\": false,\n",
      "            \"helpful_vote\": 15,\n",
      "            \"verified_purchase\": true\n",
      "        },\n",
      "        {\n",
      "            \"text\": \"The product was bad and sucked to live my expectations.\",\n",
      "            \"title\": \"Excellent Quality\",\n",
      "            \"price\": 49.99,\n",
      "            \"price_missing\": false,\n",
      "            \"helpful_vote\": 15,\n",
      "            \"verified_purchase\": true\n",
      "        },\n",
      "        {\n",
      "            \"text\": \"The product was very good.\",\n",
      "            \"title\": \"Excellent Quality\",\n",
      "            \"price\": 49.99,\n",
      "            \"price_missing\": false,\n",
      "            \"helpful_vote\": 15,\n",
      "            \"verified_purchase\": true\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\n",
      "Prediction response: \n",
      "\tPrediction(predictions=['POSITIVE', 'NEGATIVE', 'POSITIVE'], deployed_model_id='2997186233945292800', metadata=None, model_version_id='1', model_resource_name='projects/661148801406/locations/us-central1/models/67858559131451392', explanations=None)\n",
      "====================================================================================================\n",
      "Input instance: \n",
      "\t{'text': 'The product was bad and sucked to live my expectations.', 'title': 'Excellent Quality', 'price': 49.99, 'price_missing': False, 'helpful_vote': 15, 'verified_purchase': True}\n",
      "\n",
      "Formatted input JSON: \n",
      "{\n",
      "    \"instances\": [\n",
      "        {\n",
      "            \"text\": \"The product was excellent and exceeded my expectations.\",\n",
      "            \"title\": \"Excellent Quality\",\n",
      "            \"price\": 49.99,\n",
      "            \"price_missing\": false,\n",
      "            \"helpful_vote\": 15,\n",
      "            \"verified_purchase\": true\n",
      "        },\n",
      "        {\n",
      "            \"text\": \"The product was bad and sucked to live my expectations.\",\n",
      "            \"title\": \"Excellent Quality\",\n",
      "            \"price\": 49.99,\n",
      "            \"price_missing\": false,\n",
      "            \"helpful_vote\": 15,\n",
      "            \"verified_purchase\": true\n",
      "        },\n",
      "        {\n",
      "            \"text\": \"The product was very good.\",\n",
      "            \"title\": \"Excellent Quality\",\n",
      "            \"price\": 49.99,\n",
      "            \"price_missing\": false,\n",
      "            \"helpful_vote\": 15,\n",
      "            \"verified_purchase\": true\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\n",
      "Prediction response: \n",
      "\tPrediction(predictions=['POSITIVE', 'NEGATIVE', 'POSITIVE'], deployed_model_id='2997186233945292800', metadata=None, model_version_id='1', model_resource_name='projects/661148801406/locations/us-central1/models/67858559131451392', explanations=None)\n",
      "====================================================================================================\n",
      "Input instance: \n",
      "\t{'text': 'The product was very good.', 'title': 'Excellent Quality', 'price': 49.99, 'price_missing': False, 'helpful_vote': 15, 'verified_purchase': True}\n",
      "\n",
      "Formatted input JSON: \n",
      "{\n",
      "    \"instances\": [\n",
      "        {\n",
      "            \"text\": \"The product was excellent and exceeded my expectations.\",\n",
      "            \"title\": \"Excellent Quality\",\n",
      "            \"price\": 49.99,\n",
      "            \"price_missing\": false,\n",
      "            \"helpful_vote\": 15,\n",
      "            \"verified_purchase\": true\n",
      "        },\n",
      "        {\n",
      "            \"text\": \"The product was bad and sucked to live my expectations.\",\n",
      "            \"title\": \"Excellent Quality\",\n",
      "            \"price\": 49.99,\n",
      "            \"price_missing\": false,\n",
      "            \"helpful_vote\": 15,\n",
      "            \"verified_purchase\": true\n",
      "        },\n",
      "        {\n",
      "            \"text\": \"The product was very good.\",\n",
      "            \"title\": \"Excellent Quality\",\n",
      "            \"price\": 49.99,\n",
      "            \"price_missing\": false,\n",
      "            \"helpful_vote\": 15,\n",
      "            \"verified_purchase\": true\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\n",
      "Prediction response: \n",
      "\tPrediction(predictions=['POSITIVE', 'NEGATIVE', 'POSITIVE'], deployed_model_id='2997186233945292800', metadata=None, model_version_id='1', model_resource_name='projects/661148801406/locations/us-central1/models/67858559131451392', explanations=None)\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import base64\n",
    "\n",
    "test_instances = [\n",
    "    {\n",
    "        \"text\": \"The product was excellent and exceeded my expectations.\",\n",
    "        \"title\": \"Excellent Quality\",\n",
    "        \"price\": 49.99,\n",
    "        \"price_missing\": False,\n",
    "        \"helpful_vote\": 15,\n",
    "        \"verified_purchase\": True,\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"The product was bad and sucked to live my expectations.\",\n",
    "        \"title\": \"Excellent Quality\",\n",
    "        \"price\": 49.99,\n",
    "        \"price_missing\": False,\n",
    "        \"helpful_vote\": 15,\n",
    "        \"verified_purchase\": True,\n",
    "    },\n",
    "{\n",
    "            \"text\": \"The product was very good.\",\n",
    "            \"title\": \"Excellent Quality\",\n",
    "            \"price\": 49.99,\n",
    "            \"price_missing\": False,\n",
    "            \"helpful_vote\": 15,\n",
    "            \"verified_purchase\": True\n",
    "        }\n",
    "\n",
    "]\n",
    "\n",
    "print(\"=\" * 100)\n",
    "for instance in test_instances:\n",
    "    print(f\"Input instance: \\n\\t{instance}\\n\")\n",
    "    \n",
    "    formatted_input = {\"instances\": test_instances}\n",
    "    print(f\"Formatted input JSON: \\n{json.dumps(formatted_input, indent=4)}\\n\")\n",
    "\n",
    "    # Assuming `endpoint.predict()` is the method for inference\n",
    "    prediction = endpoint.predict(instances=test_instances)\n",
    "    print(f\"Prediction response: \\n\\t{prediction}\")\n",
    "    print(\"=\" * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REGION = us-central1\n",
      "ENDPOINT DISPLAY NAME = review_sentiment_bert_model-endpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENDPOINT_ID = 4555119443713196032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-prediction-aiplatform.googleapis.com/]\n",
      "ERROR: (gcloud.beta.ai.endpoints.predict) HTTPError 404: {\n",
      "  \"code\": 404,\n",
      "  \"type\": \"ModelNotFoundException\",\n",
      "  \"message\": \"Model not found: review_sentiment_bert_model\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION RESPONSE = \n"
     ]
    }
   ],
   "source": [
    "%%bash -s $REGION $endpoint_display_name\n",
    "\n",
    "REGION=$1\n",
    "endpoint_display_name=$2\n",
    "\n",
    "# get endpoint id\n",
    "\n",
    "echo \"REGION = ${REGION}\"\n",
    "echo \"ENDPOINT DISPLAY NAME = ${endpoint_display_name}\"\n",
    "endpoint_id=$(gcloud beta ai endpoints list --region ${REGION} --filter \"display_name=${endpoint_display_name}\" --format \"value(ENDPOINT_ID)\")\n",
    "echo \"ENDPOINT_ID = ${endpoint_id}\"\n",
    "\n",
    "# # call prediction endpoint\n",
    "# input_text=\"Take away the CGI and the A-list cast and you end up with film with less punch.\"\n",
    "# echo \"INPUT TEXT = ${input_text}\"\n",
    "\n",
    "prediction=$(\n",
    "echo \"\"\"\n",
    "{ \n",
    "    \"instances\": [\n",
    "        {\n",
    "            \"text\": \"The product was excellent and exceeded my expectations.\",\n",
    "            \"title\": \"Excellent Quality\",\n",
    "            \"price\": 49.99,\n",
    "            \"price_missing\": false,\n",
    "            \"helpful_vote\": 15,\n",
    "            \"verified_purchase\": true\n",
    "        },\n",
    "        {\n",
    "            \"text\": \"The product was bad and sucked to live my expectations.\",\n",
    "            \"title\": \"Excellent Quality\",\n",
    "            \"price\": 49.99,\n",
    "            \"price_missing\": false,\n",
    "            \"helpful_vote\": 15,\n",
    "            \"verified_purchase\": true\n",
    "        }\n",
    "\n",
    "    ]\n",
    "}\n",
    "\"\"\" | gcloud beta ai endpoints predict ${endpoint_id} --region=$REGION --json-request -)\n",
    "\n",
    "echo \"PREDICTION RESPONSE = ${prediction}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REGION = us-central1\n",
      "ENDPOINT DISPLAY NAME = review_sentiment_bert_model-endpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENDPOINT_ID = 4555119443713196032\n",
      "Performing prediction with ./instances.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-prediction-aiplatform.googleapis.com/]\n",
      "ERROR: (gcloud.beta.ai.endpoints.predict) HTTPError 404: {\n",
      "  \"code\": 404,\n",
      "  \"type\": \"ModelNotFoundException\",\n",
      "  \"message\": \"Model not found: review_sentiment_bert_model\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION RESPONSE = \n"
     ]
    }
   ],
   "source": [
    "%%bash -s $REGION $endpoint_display_name\n",
    "\n",
    "REGION=$1\n",
    "endpoint_display_name=$2\n",
    "\n",
    "# Get endpoint ID\n",
    "echo \"REGION = ${REGION}\"\n",
    "echo \"ENDPOINT DISPLAY NAME = ${endpoint_display_name}\"\n",
    "endpoint_id=$(gcloud beta ai endpoints list --region ${REGION} --filter \"display_name=${endpoint_display_name}\" --format \"value(ENDPOINT_ID)\")\n",
    "echo \"ENDPOINT_ID = ${endpoint_id}\"\n",
    "\n",
    "# Input JSON file path\n",
    "instances_file=\"./instances.json\"\n",
    "if [ ! -f \"$instances_file\" ]; then\n",
    "  echo \"Input file ${instances_file} not found!\"\n",
    "  exit 1\n",
    "fi\n",
    "\n",
    "# Perform prediction using the endpoint\n",
    "echo \"Performing prediction with ${instances_file}...\"\n",
    "prediction=$(gcloud beta ai endpoints predict ${endpoint_id} --region=$REGION --json-request=\"${instances_file}\")\n",
    "\n",
    "# Output the prediction result\n",
    "echo \"PREDICTION RESPONSE = ${prediction}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL_ID             DISPLAY_NAME\n",
      "9036777217039794176  review_sentiment_bert_model-v2\n",
      "3584325443177676800  finetuned-bert-classifier-7080-v1\n",
      "1653407102942576640  finetuned-bert-classifier-v1\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud beta ai models list --region=us-central1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vertex_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
