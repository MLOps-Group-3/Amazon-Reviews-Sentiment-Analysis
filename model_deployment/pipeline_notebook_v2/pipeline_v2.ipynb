{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp.v2 import dsl\n",
    "from kfp.v2.dsl import component, Input, Output, Dataset, Artifact\n",
    "from google.cloud import storage\n",
    "import os\n",
    "from google.cloud import aiplatform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Variables\n",
    "GCP_PROJECT = \"amazonreviewssentimentanalysis\"\n",
    "GCP_REGION = \"us-central1\"\n",
    "BUCKET_NAME = \"arsa_model_deployment_uscentral_v2\"\n",
    "DATA_PATH = f\"gs://{BUCKET_NAME}/input/labeled_data_10perc.csv\"\n",
    "OUTPUT_DIR = f\"gs://{BUCKET_NAME}/output/data/\"\n",
    "CODE_BUCKET_PATH = f\"gs://{BUCKET_NAME}/code\"\n",
    "# DATA_PREP_CODE = f\"gs://{BUCKET_NAME}/code/data_prep\"\n",
    "SOURCE_CODE = f\"gs://{BUCKET_NAME}/code/src\"\n",
    "SLICE_METRIC_PATH = f\"gs://{BUCKET_NAME}/output/metrics\"\n",
    "# TRAINER_CODE = f\"gs://{BUCKET_NAME}/code/trainer\"\n",
    "MODEL_SAVE_PATH = f\"gs://{BUCKET_NAME}/output/models/final_model.pth\"\n",
    "# TORCH_SERVE_PATH = f\"gs://{BUCKET_NAME}/code/predictor/\"\n",
    "VERSION = 1\n",
    "APP_NAME = \"review_sentiment_bert_model\"\n",
    "\n",
    "MODEL_DISPLAY_NAME = f\"{APP_NAME}-v{VERSION}\"\n",
    "MODEL_DESCRIPTION = \"PyTorch serve deployment model for amazon reviews sentiment classification\"\n",
    "\n",
    "# MODEL_NAME = APP_NAME\n",
    "health_route = \"/ping\"\n",
    "predict_route = f\"/predictions/{APP_NAME}\"\n",
    "serving_container_ports = [7080]\n",
    "\n",
    "PROJECT_ID = \"amazonreviewssentimentanalysis\" \n",
    "APP_NAME = \"review_sentiment_bert_model\"\n",
    "DOCKER_IMAGE_NAME = \"pytorch_predict_{APP_NAME}\"\n",
    "CUSTOM_PREDICTOR_IMAGE_URI = f\"gcr.io/{PROJECT_ID}/pytorch_predict_{APP_NAME}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hrs/anaconda3/envs/mlops_pipeline/lib/python3.9/site-packages/google/auth/_default.py:76: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "# Initialize Google Cloud Storage client\n",
    "client = storage.Client(project=GCP_PROJECT)\n",
    "bucket = client.bucket(BUCKET_NAME)\n",
    "\n",
    "# Function to upload folder to GCS\n",
    "def upload_folder_to_gcs(local_folder, bucket, destination_folder):\n",
    "    # Strip the `gs://<bucket_name>/` prefix from the destination path\n",
    "    if destination_folder.startswith(f\"gs://{bucket.name}/\"):\n",
    "        destination_folder = destination_folder[len(f\"gs://{bucket.name}/\"):]\n",
    "\n",
    "    for root, _, files in os.walk(local_folder):\n",
    "        for file in files:\n",
    "            local_path = os.path.join(root, file)\n",
    "            relative_path = os.path.relpath(local_path, local_folder)\n",
    "            print(local_path,relative_path)\n",
    "\n",
    "            gcs_path = os.path.join(destination_folder, local_path).replace(\"\\\\\", \"/\")\n",
    "            blob = bucket.blob(gcs_path)\n",
    "            blob.upload_from_filename(local_path)\n",
    "            print(f\"Uploaded {local_path} to gs://{bucket.name}/{gcs_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src/app.py app.py\n",
      "Uploaded src/app.py to gs://arsa_model_deployment_uscentral_v2/code/src/app.py\n",
      "src/app_requirements.txt app_requirements.txt\n",
      "Uploaded src/app_requirements.txt to gs://arsa_model_deployment_uscentral_v2/code/src/app_requirements.txt\n",
      "src/bert_model_torch_serve.py bert_model_torch_serve.py\n",
      "Uploaded src/bert_model_torch_serve.py to gs://arsa_model_deployment_uscentral_v2/code/src/bert_model_torch_serve.py\n",
      "src/best_hyperparameters.json best_hyperparameters.json\n",
      "Uploaded src/best_hyperparameters.json to gs://arsa_model_deployment_uscentral_v2/code/src/best_hyperparameters.json\n",
      "src/bias_detect.py bias_detect.py\n",
      "Uploaded src/bias_detect.py to gs://arsa_model_deployment_uscentral_v2/code/src/bias_detect.py\n",
      "src/config.py config.py\n",
      "Uploaded src/config.py to gs://arsa_model_deployment_uscentral_v2/code/src/config.py\n",
      "src/custom_handler.py custom_handler.py\n",
      "Uploaded src/custom_handler.py to gs://arsa_model_deployment_uscentral_v2/code/src/custom_handler.py\n",
      "src/Dockerfile Dockerfile\n",
      "Uploaded src/Dockerfile to gs://arsa_model_deployment_uscentral_v2/code/src/Dockerfile\n",
      "src/evaluate_model.py evaluate_model.py\n",
      "Uploaded src/evaluate_model.py to gs://arsa_model_deployment_uscentral_v2/code/src/evaluate_model.py\n",
      "src/evaluate_model_slices.py evaluate_model_slices.py\n",
      "Uploaded src/evaluate_model_slices.py to gs://arsa_model_deployment_uscentral_v2/code/src/evaluate_model_slices.py\n",
      "src/experiment_runner.py experiment_runner.py\n",
      "Uploaded src/experiment_runner.py to gs://arsa_model_deployment_uscentral_v2/code/src/experiment_runner.py\n",
      "src/experiment_runner_optuna.py experiment_runner_optuna.py\n",
      "Uploaded src/experiment_runner_optuna.py to gs://arsa_model_deployment_uscentral_v2/code/src/experiment_runner_optuna.py\n",
      "src/index_to_name.json index_to_name.json\n",
      "Uploaded src/index_to_name.json to gs://arsa_model_deployment_uscentral_v2/code/src/index_to_name.json\n",
      "src/prepare_data.py prepare_data.py\n",
      "Uploaded src/prepare_data.py to gs://arsa_model_deployment_uscentral_v2/code/src/prepare_data.py\n",
      "src/README.md README.md\n",
      "Uploaded src/README.md to gs://arsa_model_deployment_uscentral_v2/code/src/README.md\n",
      "src/train_save.py train_save.py\n",
      "Uploaded src/train_save.py to gs://arsa_model_deployment_uscentral_v2/code/src/train_save.py\n",
      "src/data/label_encoder.pkl data/label_encoder.pkl\n",
      "Uploaded src/data/label_encoder.pkl to gs://arsa_model_deployment_uscentral_v2/code/src/data/label_encoder.pkl\n",
      "src/data/slice_metrics.csv data/slice_metrics.csv\n",
      "Uploaded src/data/slice_metrics.csv to gs://arsa_model_deployment_uscentral_v2/code/src/data/slice_metrics.csv\n",
      "src/data/test.pkl data/test.pkl\n",
      "Uploaded src/data/test.pkl to gs://arsa_model_deployment_uscentral_v2/code/src/data/test.pkl\n",
      "src/data/train.pkl data/train.pkl\n",
      "Uploaded src/data/train.pkl to gs://arsa_model_deployment_uscentral_v2/code/src/data/train.pkl\n",
      "src/data/val.pkl data/val.pkl\n",
      "Uploaded src/data/val.pkl to gs://arsa_model_deployment_uscentral_v2/code/src/data/val.pkl\n",
      "src/utils/bert_model.py utils/bert_model.py\n",
      "Uploaded src/utils/bert_model.py to gs://arsa_model_deployment_uscentral_v2/code/src/utils/bert_model.py\n",
      "src/utils/data_loader.py utils/data_loader.py\n",
      "Uploaded src/utils/data_loader.py to gs://arsa_model_deployment_uscentral_v2/code/src/utils/data_loader.py\n",
      "src/utils/roberta_model.py utils/roberta_model.py\n",
      "Uploaded src/utils/roberta_model.py to gs://arsa_model_deployment_uscentral_v2/code/src/utils/roberta_model.py\n",
      "src/utils/__init__.py utils/__init__.py\n",
      "Uploaded src/utils/__init__.py to gs://arsa_model_deployment_uscentral_v2/code/src/utils/__init__.py\n",
      "src/utils/__pycache__/bert_model.cpython-312.pyc utils/__pycache__/bert_model.cpython-312.pyc\n",
      "Uploaded src/utils/__pycache__/bert_model.cpython-312.pyc to gs://arsa_model_deployment_uscentral_v2/code/src/utils/__pycache__/bert_model.cpython-312.pyc\n",
      "src/utils/__pycache__/data_loader.cpython-312.pyc utils/__pycache__/data_loader.cpython-312.pyc\n",
      "Uploaded src/utils/__pycache__/data_loader.cpython-312.pyc to gs://arsa_model_deployment_uscentral_v2/code/src/utils/__pycache__/data_loader.cpython-312.pyc\n",
      "src/utils/__pycache__/roberta_model.cpython-312.pyc utils/__pycache__/roberta_model.cpython-312.pyc\n",
      "Uploaded src/utils/__pycache__/roberta_model.cpython-312.pyc to gs://arsa_model_deployment_uscentral_v2/code/src/utils/__pycache__/roberta_model.cpython-312.pyc\n",
      "src/utils/__pycache__/__init__.cpython-312.pyc utils/__pycache__/__init__.cpython-312.pyc\n",
      "Uploaded src/utils/__pycache__/__init__.cpython-312.pyc to gs://arsa_model_deployment_uscentral_v2/code/src/utils/__pycache__/__init__.cpython-312.pyc\n",
      "src/__pycache__/config.cpython-312.pyc __pycache__/config.cpython-312.pyc\n",
      "Uploaded src/__pycache__/config.cpython-312.pyc to gs://arsa_model_deployment_uscentral_v2/code/src/__pycache__/config.cpython-312.pyc\n",
      "src/__pycache__/evaluate_model.cpython-312.pyc __pycache__/evaluate_model.cpython-312.pyc\n",
      "Uploaded src/__pycache__/evaluate_model.cpython-312.pyc to gs://arsa_model_deployment_uscentral_v2/code/src/__pycache__/evaluate_model.cpython-312.pyc\n"
     ]
    }
   ],
   "source": [
    "upload_folder_to_gcs(\"src\", bucket, CODE_BUCKET_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hrs/anaconda3/envs/mlops_pipeline/lib/python3.9/site-packages/kfp/dsl/component_decorator.py:119: FutureWarning: Python 3.7 has reached end-of-life. The default base_image used by the @dsl.component decorator will switch from 'python:3.7' to 'python:3.8' on April 23, 2024. To ensure your existing components work with versions of the KFP SDK released after that date, you should provide an explicit base_image argument and ensure your component works as intended on Python 3.8.\n",
      "  return component_factory.create_component_from_func(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/661148801406/locations/us-central1/pipelineJobs/data-prep-and-train-20241202112630\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/661148801406/locations/us-central1/pipelineJobs/data-prep-and-train-20241202112630')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/data-prep-and-train-20241202112630?project=661148801406\n"
     ]
    }
   ],
   "source": [
    "from kfp.v2.dsl import (\n",
    "    Input,\n",
    "    Output,\n",
    "    Artifact,\n",
    "    Dataset,\n",
    "    Model,\n",
    "    Metrics,\n",
    "    component,\n",
    "    pipeline,\n",
    ")\n",
    "from typing import NamedTuple\n",
    "@component(\n",
    "    packages_to_install=[\"pandas\", \"scikit-learn\", \"google-cloud-storage\", \"torch\", \"gcsfs\",\"arsa-pipeline-tools\"],\n",
    ")\n",
    "def data_prep_stage(\n",
    "    code_bucket_path: str,\n",
    "    input_path: str,\n",
    "    output_dir: str,\n",
    "    train_data: Output[Dataset],\n",
    "    val_data: Output[Dataset],\n",
    "    test_data: Output[Dataset],\n",
    "\n",
    "):\n",
    "    import os\n",
    "    import sys\n",
    "    import importlib.util\n",
    "    import pandas as pd\n",
    "    from google.cloud import storage\n",
    "    from arsa_pipeline_tools.utils import download_files_from_gcs, load_module_from_file\n",
    "    # Logging setup\n",
    "    import logging\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    code_dir = \"/tmp/code\"\n",
    "    os.makedirs(code_dir, exist_ok=True)\n",
    "\n",
    "    download_files_from_gcs(code_bucket_path,code_dir)\n",
    "    logger.info(f\"Files in {code_dir}: {os.listdir(code_dir)}\")\n",
    "    sys.path.insert(0, code_dir)\n",
    "\n",
    "    prepare_data_module = load_module_from_file(f\"{code_dir}/prepare_data.py\")\n",
    "    train_df, val_df, test_df, label_encoder = prepare_data_module.split_and_save_data(input_path, output_dir)\n",
    "    train_df.to_pickle(train_data.path)\n",
    "    val_df.to_pickle(val_data.path)\n",
    "    test_df.to_pickle(test_data.path)\n",
    "    # label_encoder.to_pickle(label_encoder_data.path)\n",
    "    logger.info(\"Artifacts for train, dev, and test data created successfully.\")\n",
    "\n",
    "\n",
    "@component(\n",
    "    packages_to_install=[\n",
    "        \"optuna\",\n",
    "        \"mlflow\",\n",
    "        \"torch==1.12.1\",  # PyTorch version 1.12.1, verified to work with transformers and accelerate\n",
    "        \"transformers==4.21.0\",  # Compatible with PyTorch 1.12\n",
    "        \"numpy\",\n",
    "        \"google-cloud-storage\",\n",
    "        \"scikit-learn\",\n",
    "        \"arsa-pipeline-tools\",\n",
    "    ],\n",
    "    base_image=\"us-docker.pkg.dev/vertex-ai/training/pytorch-gpu.1-12.py310:latest\",  # Python 3.10 with GPU support\n",
    ")\n",
    "def run_optuna_experiment(\n",
    "    code_bucket_path: str,\n",
    "    data_path: str,\n",
    "    train_data: Input[Dataset],\n",
    "    val_data: Input[Dataset],\n",
    "    test_data: Input[Dataset],\n",
    "    best_hyperparams_metrics: Output[Metrics],\n",
    "):\n",
    "    import os\n",
    "    import sys\n",
    "    import importlib.util\n",
    "    import logging\n",
    "    from google.cloud import storage\n",
    "    from arsa_pipeline_tools.utils import download_files_from_gcs, load_module_from_file\n",
    "\n",
    "    # Logging setup\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    code_dir = \"/tmp/code\"\n",
    "    os.makedirs(code_dir, exist_ok=True)\n",
    "    ALLOWED_EXTENSIONS = {\".py\", \".json\", \".yaml\"}\n",
    "\n",
    "    download_files_from_gcs(code_bucket_path,code_dir,ALLOWED_EXTENSIONS)\n",
    "\n",
    "    logger.info(f\"Files in {code_dir}: {os.listdir(code_dir)}\")\n",
    "    sys.path.insert(0, code_dir)\n",
    "\n",
    "    # Ensure `experiment_runner_optuna.py` exists\n",
    "    script_path = os.path.join(code_dir, \"experiment_runner_optuna.py\")\n",
    "    if not os.path.exists(script_path):\n",
    "        raise FileNotFoundError(f\"`experiment_runner_optuna.py` not found in {code_dir}\")\n",
    "\n",
    "    # Load and execute the experiment\n",
    "    experiment_module = load_module_from_file(script_path)\n",
    "\n",
    "    # Run the Optuna experiment\n",
    "    best_hyperparameters = experiment_module.find_best_hyperparameters(data_path)\n",
    "    logger.info(best_hyperparameters)\n",
    "    # Save the best hyperparameters to the output artifact\n",
    "    # Log hyperparameters to Metrics artifact\n",
    "    for key, value in best_hyperparameters.items():\n",
    "        best_hyperparams_metrics.log_metric(key, value)\n",
    "\n",
    "@component(\n",
    "    # packages_to_install=[\"torch\", \"google-cloud-storage\", \"transformers\", \"pandas\", \"scikit-learn\", \"gcsfs\",\"accelerate\"],\n",
    "    packages_to_install=[\n",
    "        \"pandas\",\n",
    "        \"torch==1.12.1\",  # PyTorch version 1.12.1, verified to work with transformers and accelerate\n",
    "        \"transformers==4.21.0\",  # Compatible with PyTorch 1.12\n",
    "        \"scikit-learn\",\n",
    "        \"accelerate==0.12.0\",  # Compatible with PyTorch 1.12 and transformers\n",
    "        \"google-cloud-storage\",\n",
    "        # \"kfp==2.0.0\",  # Compatible version of kfp\n",
    "        \"PyYAML>=6.0\",  # A stable version compatible with the other libraries\n",
    "        \"tensorboard\",\n",
    "        \"arsa-pipeline-tools\",\n",
    "    ],\n",
    "    base_image=\"us-docker.pkg.dev/vertex-ai/training/pytorch-gpu.1-12.py310:latest\",  # Python 3.10 with GPU support\n",
    ")\n",
    "def train_save_stage(\n",
    "    code_bucket_path: str,\n",
    "    data_path: str,\n",
    "    model_save_path: str,\n",
    "    train_data: Input[Dataset],\n",
    "    val_data: Input[Dataset],\n",
    "    best_hyperparams_metrics: Input[Metrics],\n",
    "    model: Output[Model],\n",
    "    model_metrics: Output[Metrics],\n",
    "    \n",
    "\n",
    "):\n",
    "    import os\n",
    "    import sys\n",
    "    import logging\n",
    "    from google.cloud import storage\n",
    "    import importlib.util\n",
    "    from accelerate import Accelerator\n",
    "    from arsa_pipeline_tools.utils import download_files_from_gcs, load_module_from_file\n",
    "\n",
    "\n",
    "    # Logging setup\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    logger = logging.getLogger(__name__)\n",
    "    # Initialize Accelerator\n",
    "    accelerator = Accelerator()\n",
    "    \n",
    "    # Check available device\n",
    "    logger.info(f\"Using device: {accelerator.device}\")\n",
    "\n",
    "\n",
    "    code_dir = \"/tmp/code\"\n",
    "    os.makedirs(code_dir, exist_ok=True)\n",
    "    ALLOWED_EXTENSIONS = {\".py\", \".json\", \".yaml\", \".csv\", \".pkl\"}\n",
    "\n",
    "    download_files_from_gcs(code_bucket_path,code_dir,ALLOWED_EXTENSIONS)\n",
    "\n",
    "    logger.info(f\"Files in {code_dir}: {os.listdir(code_dir)}\")\n",
    "    sys.path.insert(0, code_dir)\n",
    "\n",
    "    train_save_module = load_module_from_file(f\"{code_dir}/train_save.py\")\n",
    "    hyperparameters_path = os.path.join(code_dir, \"best_hyperparameters.json\")\n",
    "\n",
    "    best_hyperparams = {key: value for key, value in best_hyperparams_metrics.metadata.items()}\n",
    "    logger.info(f\"Read best hyperparameters from metrics: {best_hyperparams}\")\n",
    "\n",
    "    returned_model_path, epoch_metrics = train_save_module.train_and_save_final_model(\n",
    "        hyperparameters=best_hyperparams,  #train_save_module.load_hyperparameters(hyperparameters_path),\n",
    "        data_path=data_path,\n",
    "        train_data = train_data,\n",
    "        val_data = val_data, \n",
    "        model_save_path=model_save_path,\n",
    "    )\n",
    "\n",
    "\n",
    "    model.metadata[\"gcs_path\"] = returned_model_path\n",
    "    logger.info(f\"Model artifact metadata updated with GCS path: {returned_model_path}\")\n",
    "\n",
    "    print(epoch_metrics)\n",
    "    logger.info(f\"epoch_metrics: {epoch_metrics}\")\n",
    "    # Log metrics to the Vertex AI UI\n",
    "    # Corrected logging for Vertex AI\n",
    "    for epoch, metric in enumerate(epoch_metrics, start=1):\n",
    "        # Log accuracy and loss (ensure keys match)\n",
    "        model_metrics.log_metric(f\"epoch_{epoch}_accuracy\", metric[\"eval_accuracy\"])\n",
    "        model_metrics.log_metric(f\"epoch_{epoch}_loss\", metric[\"eval_loss\"])\n",
    "        model_metrics.log_metric(f\"epoch_{epoch}_precision\", metric[\"eval_precision\"])\n",
    "        model_metrics.log_metric(f\"epoch_{epoch}_recall\", metric[\"eval_recall\"])\n",
    "        model_metrics.log_metric(f\"epoch_{epoch}_f1\", metric[\"eval_f1\"])\n",
    "\n",
    "        # metrics.log_metric(f\"epoch_{epoch}_runtime\", metric[\"eval_runtime\"])\n",
    "        # metrics.log_metric(f\"epoch_{epoch}_samples_per_second\", metric[\"eval_samples_per_second\"])\n",
    "        # metrics.log_metric(f\"epoch_{epoch}_steps_per_second\", metric[\"eval_steps_per_second\"])\n",
    "        \n",
    "        # Log to standard output\n",
    "        logger.info(f\"Logged metrics for epoch {epoch}: {metric}\")\n",
    "\n",
    "@component(\n",
    "    packages_to_install=[\n",
    "        \"torch==1.12.1\",  # PyTorch version 1.12.1, verified to work with transformers and accelerate\n",
    "        \"transformers==4.21.0\",  # Compatible with PyTorch 1.12\n",
    "        \"pandas\",\n",
    "        \"scikit-learn\",\n",
    "        \"google-cloud-storage\",\n",
    "        \"gcsfs\",\n",
    "        \"arsa-pipeline-tools\",\n",
    "    ],\n",
    "    base_image=\"python:3.9\",\n",
    ")\n",
    "def evaluate_model_component(\n",
    "    code_bucket_path: str,\n",
    "    model_gcs_path: Input[Model],\n",
    "    test_data: Input[Dataset],\n",
    "    eval_metrics: Output[Metrics],\n",
    "    # f1_score: Output[float],\n",
    "    f1_threshold: float = 0.6,\n",
    ")-> NamedTuple(\"output\", [(\"eval_pass\", str)]):\n",
    "    import logging\n",
    "    import json\n",
    "    import importlib.util\n",
    "    from google.cloud import storage\n",
    "    import os\n",
    "    import sys\n",
    "    from arsa_pipeline_tools.utils import download_files_from_gcs, load_module_from_file\n",
    "\n",
    "\n",
    "    # Logging setup\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "    code_dir = \"/tmp/code\"\n",
    "    os.makedirs(code_dir, exist_ok=True)\n",
    "    ALLOWED_EXTENSIONS = {\".py\", \".json\", \".yaml\", \".csv\", \".pkl\"}\n",
    "    download_files_from_gcs(code_bucket_path,code_dir,ALLOWED_EXTENSIONS)\n",
    "\n",
    "\n",
    "    logger.info(f\"Files in {code_dir}: {os.listdir(code_dir)}\")\n",
    "    sys.path.insert(0, code_dir)\n",
    "\n",
    "    # Ensure `evaluate_model.py` exists\n",
    "    evaluate_script_path = os.path.join(code_dir, \"evaluate_model.py\")\n",
    "    if not os.path.exists(evaluate_script_path):\n",
    "        raise FileNotFoundError(f\"`evaluate_model.py` not found in {code_dir}\")\n",
    "\n",
    "    # Load `evaluate_model.py` dynamically\n",
    "    evaluate_module = load_module_from_file(evaluate_script_path)\n",
    "\n",
    "    logger.info(f\"model_gcs_path : {model_gcs_path},\\t model_gcs_path.uri {model_gcs_path.uri}, metadata {model_gcs_path.metadata['gcs_path']}\")\n",
    "    # Call `gcp_eval` method from the module\n",
    "    accuracy, precision, recall, f1 = evaluate_module.gcp_eval(\n",
    "        test_df=test_data,\n",
    "        model_path=model_gcs_path.metadata[\"gcs_path\"],\n",
    "    )\n",
    "\n",
    "    # Log metrics to Vertex AI\n",
    "    eval_metrics.log_metric(\"accuracy\", accuracy)\n",
    "    eval_metrics.log_metric(\"precision\", precision)\n",
    "    eval_metrics.log_metric(\"recall\", recall)\n",
    "    eval_metrics.log_metric(\"f1\", f1)\n",
    "    # Conditional check\n",
    "    if f1 >= f1_threshold:\n",
    "        logger.info(f\"Model passed the F1 threshold: {f1:.4f} >= {f1_threshold}\")\n",
    "        eval_pass = \"true\"\n",
    "        return (eval_pass,)\n",
    "    else:\n",
    "        logger.error(f\"Model failed to meet the F1 threshold: {f1:.4f} < {f1_threshold}\")\n",
    "        eval_pass = \"false\"\n",
    "        return (eval_pass,)\n",
    "\n",
    "        # raise ValueError(f\"F1 score {f1:.4f} is below the threshold {f1_threshold}\")\n",
    "\n",
    "@component(\n",
    "    packages_to_install=[\n",
    "        \"torch==1.12.1\",  # PyTorch version 1.12.1, verified to work with transformers and accelerate\n",
    "        \"transformers==4.21.0\",  # Compatible with PyTorch 1.12\n",
    "        \"pandas\",\n",
    "        \"scikit-learn\",\n",
    "        \"google-cloud-storage\",\n",
    "        \"gcsfs\",\n",
    "        \"arsa-pipeline-tools\",\n",
    "    ],\n",
    "    base_image=\"python:3.9\",\n",
    ")\n",
    "def evaluate_slices_component(\n",
    "    code_bucket_path: str,\n",
    "    model_gcs_path: Input[Model],\n",
    "    test_data: Input[Dataset],\n",
    "    eval_slices_metrics: Output[Metrics],\n",
    "    gcs_artifact_path: str,\n",
    "    f1_threshold: float = 0.6,\n",
    "):\n",
    "    import logging\n",
    "    import json\n",
    "    import importlib.util\n",
    "    from google.cloud import storage\n",
    "    import os\n",
    "    import sys\n",
    "    from arsa_pipeline_tools.utils import download_files_from_gcs, load_module_from_file\n",
    "\n",
    "\n",
    "    # Logging setup\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "    code_dir = \"/tmp/code\"\n",
    "    os.makedirs(code_dir, exist_ok=True)\n",
    "    ALLOWED_EXTENSIONS = {\".py\", \".json\", \".yaml\", \".csv\", \".pkl\"}\n",
    "\n",
    "    download_files_from_gcs(code_bucket_path,code_dir,ALLOWED_EXTENSIONS)\n",
    "    logger.info(f\"Files in {code_dir}: {os.listdir(code_dir)}\")\n",
    "    sys.path.insert(0, code_dir)\n",
    "\n",
    "    # Ensure `evaluate_module_slices.py` exists\n",
    "    evaluate_script_path = os.path.join(code_dir, \"evaluate_model_slices.py\")\n",
    "    if not os.path.exists(evaluate_script_path):\n",
    "        raise FileNotFoundError(f\"`evaluate_module_slices.py` not found in {code_dir}\")\n",
    "\n",
    "    # Load `evaluate_module_slices.py` dynamically\n",
    "    evaluate_module_slices = load_module_from_file(evaluate_script_path)\n",
    "\n",
    "    logger.info(f\"model_gcs_path : {model_gcs_path},\\t model_gcs_path.uri {model_gcs_path.uri}, metadata {model_gcs_path.metadata['gcs_path']}\")\n",
    "    # Call `gcp_eval` method from the module\n",
    "    metrics_df = evaluate_module_slices.gcp_eval_slices(\n",
    "        test_df=test_data,\n",
    "        model_path=model_gcs_path.metadata[\"gcs_path\"],\n",
    "    )\n",
    "    logger.info(metrics_df)\n",
    "\n",
    "    gcs_bucket_name = gcs_artifact_path.split('/')[2]\n",
    "    gcs_blob_path = '/'.join(gcs_artifact_path.split('/')[3:])\n",
    "    csv_filename = f\"{gcs_blob_path}/slice_metrics.csv\"\n",
    "    json_filename = f\"{gcs_blob_path}/slice_metrics.json\"\n",
    "    \n",
    "    client = storage.Client()\n",
    "\n",
    "    bucket = client.bucket(gcs_bucket_name)\n",
    "\n",
    "    # Save as CSV\n",
    "    csv_blob = bucket.blob(csv_filename)\n",
    "    csv_blob.upload_from_string(metrics_df.to_csv(index=False), content_type=\"text/csv\")\n",
    "    logger.info(f\"Slice metrics saved to GCS as CSV at gs://{gcs_bucket_name}/{csv_filename}\")\n",
    "\n",
    "    # Save as JSON\n",
    "    json_blob = bucket.blob(json_filename)\n",
    "    json_blob.upload_from_string(metrics_df.to_json(orient=\"records\"), content_type=\"application/json\")\n",
    "    logger.info(f\"Slice metrics saved to GCS as JSON at gs://{gcs_bucket_name}/{json_filename}\")\n",
    "\n",
    "    # Log paths of the artifacts in metrics\n",
    "    eval_slices_metrics.metadata[\"slice_metrics_csv\"] = f\"gs://{gcs_bucket_name}/{csv_filename}\"\n",
    "    eval_slices_metrics.metadata[\"slice_metrics_json\"] = f\"gs://{gcs_bucket_name}/{json_filename}\"\n",
    "\n",
    "@component(\n",
    "    packages_to_install=[\n",
    "        \"torch==1.12.1\",  # PyTorch version 1.12.1, verified to work with transformers and accelerate\n",
    "        \"transformers==4.21.0\",  # Compatible with PyTorch 1.12\n",
    "        \"pandas\",\n",
    "        \"scikit-learn\",\n",
    "        \"google-cloud-storage\",\n",
    "        \"gcsfs\",\n",
    "        \"arsa-pipeline-tools\",\n",
    "    ],\n",
    "    base_image=\"python:3.9\",\n",
    ")\n",
    "def bias_detect_component(\n",
    "    code_bucket_path: str,\n",
    "    metrics: Input[Metrics],\n",
    "    gcs_artifact_path: str,\n",
    ")-> NamedTuple(\"output\", [(\"bias_detect\", str)]):\n",
    "    import logging\n",
    "    import json\n",
    "    import importlib.util\n",
    "    from google.cloud import storage\n",
    "    import os\n",
    "    import sys\n",
    "    from arsa_pipeline_tools.utils import download_files_from_gcs, load_module_from_file\n",
    "\n",
    "\n",
    "\n",
    "    # Logging setup\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    # Download code from GCS\n",
    "\n",
    "    code_dir = \"/tmp/code\"\n",
    "    os.makedirs(code_dir, exist_ok=True)\n",
    "    ALLOWED_EXTENSIONS = {\".py\", \".json\", \".yaml\", \".csv\", \".pkl\"}\n",
    "    \n",
    "    download_files_from_gcs(code_bucket_path,code_dir,ALLOWED_EXTENSIONS)\n",
    "    logger.info(f\"Files in {code_dir}: {os.listdir(code_dir)}\")\n",
    "    sys.path.insert(0, code_dir)\n",
    "\n",
    "    # Ensure `evaluate_module_slices.py` exists\n",
    "    evaluate_script_path = os.path.join(code_dir, \"bias_detect.py\")\n",
    "    if not os.path.exists(evaluate_script_path):\n",
    "        raise FileNotFoundError(f\"`evaluate_module_slices.py` not found in {code_dir}\")\n",
    "\n",
    "    # Load `evaluate_module_slices.py` dynamically\n",
    "    bias_detect = load_module_from_file(evaluate_script_path)\n",
    "\n",
    "\n",
    "    # Call `gcp_eval` method from the module\n",
    "    biased_rows, f1_threshold = bias_detect.detect_bias(\n",
    "        slice_metrics_path=metrics.metadata[\"slice_metrics_csv\"],\n",
    "    )\n",
    "    bias_report = {}\n",
    "\n",
    "    # Log results\n",
    "    if not biased_rows.empty:\n",
    "        bias_report[\"bias_detected\"] = True\n",
    "        bias_report[\"details\"] = biased_rows.to_dict(orient=\"records\")\n",
    "\n",
    "        logger.warning(\"Potential bias detected in the following slices:\")\n",
    "        for _, row in biased_rows.iterrows():\n",
    "            logger.error(\n",
    "                f\"Slice Column: {row['Slice Column']}, Slice Value: {row['Slice Value']}, \"\n",
    "                f\"Samples: {row['Samples']}, F1 Score: {row['F1 Score']:.4f} (Threshold: {f1_threshold:.4f})\"\n",
    "            )\n",
    "        logger.error(\"Potential bias detected. Check bias_detection.log for details.\")\n",
    "    else:\n",
    "        bias_report[\"bias_detected\"] = False\n",
    "        bias_report[\"details\"] = []\n",
    "        logger.info(\"No significant bias detected.\")\n",
    "        # print(\"No significant bias detected.\")\n",
    "\n",
    "    # Save bias report as JSON to GCS\n",
    "    gcs_bucket_name = gcs_artifact_path.split('/')[2]\n",
    "    gcs_blob_path = '/'.join(gcs_artifact_path.split('/')[3:])\n",
    "    bias_json_path = f\"{gcs_blob_path}/bias.json\"\n",
    "\n",
    "    try:\n",
    "        client = storage.Client()\n",
    "        bucket = client.bucket(gcs_bucket_name)\n",
    "        blob = bucket.blob(bias_json_path)\n",
    "        blob.upload_from_string(json.dumps(bias_report, indent=4), content_type=\"application/json\")\n",
    "        logging.info(f\"Bias report saved to GCS at gs://{gcs_bucket_name}/{bias_json_path}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to save bias report to GCS: {e}\")\n",
    "        raise\n",
    "\n",
    "    # bias_metrics.log_metric(\"bias_detected\",)\n",
    "    \n",
    "    # Raise an error if bias is detected to stop the pipeline\n",
    "    if bias_report[\"bias_detected\"]:\n",
    "        # bias_metrics.log_metric(\"bias_detected\",True)\n",
    "        bias_detect = \"true\"\n",
    "        return (bias_detect,)\n",
    "        # raise RuntimeError(\"Bias detected in slice metrics. Stopping the pipeline.\")\n",
    "    else:\n",
    "        bias_detect = \"false\"\n",
    "        return (bias_detect,)\n",
    "        # bias_metrics.log_metric(\"bias_detected\",False)\n",
    "\n",
    "\n",
    "@component(\n",
    "    packages_to_install=[\"google-cloud-storage\", \"google-cloud-build\"],\n",
    "    base_image=\"python:3.9\",\n",
    ")\n",
    "def build_and_push_torchserve_image(\n",
    "    code_bucket_path: str,\n",
    "    gcp_project: str, \n",
    "    gcp_region: str, \n",
    "    bucket_name: str, \n",
    "    docker_image_name: str,\n",
    "    model_gcs_path: Input[Model]\n",
    "):\n",
    "    # Import inside the component\n",
    "    from google.cloud.devtools import cloudbuild_v1 as cloudbuild\n",
    "    from google.cloud import storage\n",
    "    import logging\n",
    "    import os\n",
    "    # Set up logging\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    # Define environment variables\n",
    "    TORCH_SERVE_PATH = f\"gs://{bucket_name}/code/predictor/\"\n",
    "    CUSTOM_PREDICTOR_IMAGE_URI = f\"gcr.io/{gcp_project}/{docker_image_name}\"\n",
    "\n",
    "    # Set up the CloudBuild client\n",
    "    client = cloudbuild.CloudBuildClient()\n",
    "\n",
    "    # Log the environment variables for debugging\n",
    "    logger.info(f\"GCP Project: {gcp_project}\")\n",
    "    logger.info(f\"GCP Region: {gcp_region}\")\n",
    "    logger.info(f\"Bucket Name: {bucket_name}\")\n",
    "    logger.info(f\"TorchServe Path: {TORCH_SERVE_PATH}\")\n",
    "    logger.info(f\"Docker Image Name: {docker_image_name}\")\n",
    "    logger.info(f\"Custom Docker Image URI: {CUSTOM_PREDICTOR_IMAGE_URI}\")\n",
    "        \n",
    "    model_gcs_path = model_gcs_path.metadata[\"gcs_path\"]\n",
    "    logger.info(model_gcs_path)\n",
    "    model_gcs_path = f\"gs://{bucket_name}/output/models/\"\n",
    "    # Create Cloud Build configuration (cloudbuild.yaml)\n",
    "    cloudbuild_config = {\n",
    "        'steps': [\n",
    "            # Step 1: Download code files from GCS\n",
    "            {\n",
    "                \"name\": \"gcr.io/cloud-builders/gsutil\",\n",
    "                \"args\": [\n",
    "                    'cp',\n",
    "                    '-r',  # Recursive copy\n",
    "                    f'{code_bucket_path}/*',  # Copy all contents from the code folder\n",
    "                    '.'  # Copy to the current working directory\n",
    "                ],\n",
    "            },\n",
    "            # Step 2: Create the destination directory for model files\n",
    "            {\n",
    "                \"name\": \"ubuntu\",\n",
    "                \"args\": [\n",
    "                    \"mkdir\",\n",
    "                    \"-p\",  # Create parent directories as needed\n",
    "                    \"./bert-sent-model\"\n",
    "                ],\n",
    "            },\n",
    "            # Step 3: Download model files from GCS\n",
    "            {\n",
    "                \"name\": \"gcr.io/cloud-builders/gsutil\",\n",
    "                \"args\": [\n",
    "                    'cp',\n",
    "                    '-r',  # Recursive copy\n",
    "                    f'{model_gcs_path}*',  # Add wildcard to include all files in the folder\n",
    "                    './bert-sent-model/'  # Ensure the trailing slash\n",
    "                ],\n",
    "            },\n",
    "            # Step 3: List files in the current working directory\n",
    "            {\n",
    "                \"name\": \"ubuntu\",\n",
    "                \"args\": [\n",
    "                    \"ls\",\n",
    "                    \"-R\",  # Recursive listing\n",
    "                    \".\"    # Current working directory\n",
    "                ],\n",
    "            },\n",
    "            # Step 4: Build the Docker image\n",
    "            {\n",
    "                'name': 'gcr.io/cloud-builders/docker',\n",
    "                'args': [\n",
    "                    'build',\n",
    "                    '-t',\n",
    "                    CUSTOM_PREDICTOR_IMAGE_URI,\n",
    "                    '.'\n",
    "                ],\n",
    "            },\n",
    "            # Step 5: Push the Docker image to the container registry\n",
    "            {\n",
    "                'name': 'gcr.io/cloud-builders/docker',\n",
    "                'args': [\n",
    "                    'push',\n",
    "                    CUSTOM_PREDICTOR_IMAGE_URI\n",
    "                ],\n",
    "            },\n",
    "        ],\n",
    "        'images': [CUSTOM_PREDICTOR_IMAGE_URI],\n",
    "    }\n",
    "\n",
    "    # Create a Cloud Build build request\n",
    "    build = cloudbuild.Build(\n",
    "        steps=cloudbuild_config['steps'],\n",
    "        images=cloudbuild_config['images'],\n",
    "    )\n",
    "\n",
    "    # Trigger Cloud Build job\n",
    "    build_response = client.create_build(project_id=gcp_project, build=build)\n",
    "\n",
    "    logging.info(\"IN PROGRESS:\")\n",
    "    logging.info(build_response.metadata)\n",
    "\n",
    "    # get build status\n",
    "    result = build_response.result()\n",
    "    logging.info(\"RESULT:\", result.status)\n",
    "\n",
    "@component(\n",
    "    packages_to_install=[\"google-cloud-aiplatform\", \"google-auth\"],\n",
    "    base_image=\"python:3.9\",\n",
    ")\n",
    "def upload_model_to_registry(\n",
    "    project_id: str,\n",
    "    region: str,\n",
    "    bucket_name: str,\n",
    "    model_display_name: str,\n",
    "    docker_image_uri: str,\n",
    "    model_description: str,\n",
    "    app_name: str,\n",
    "    health_route: str = \"/ping\",\n",
    "    predict_route: str = \"/predictions/\",\n",
    "    serving_container_ports: list = [7080],\n",
    ") -> NamedTuple(\"Outputs\", [(\"model_display_name\", str), (\"model_resource_name\", str), (\"model_version\", str)]):\n",
    "    \"\"\"Uploads the model to the AI platform and ensures versioning.\"\"\"\n",
    "    from google.cloud import aiplatform\n",
    "\n",
    "    # Initialize the AI Platform\n",
    "    aiplatform.init(project=project_id, location=region, staging_bucket=bucket_name)\n",
    "\n",
    "    # Check if the model with the same display name exists\n",
    "    existing_models = aiplatform.Model.list(filter=f\"display_name={model_display_name}\")\n",
    "    \n",
    "    if existing_models:\n",
    "        # Model exists, register as a new version\n",
    "        model_resource_name = existing_models[0].resource_name\n",
    "        print(f\"Model with display name '{model_display_name}' exists. Registering as a new version.\")\n",
    "        model_version = f\"v{len(existing_models) + 1}\"  # Increment version number\n",
    "    else:\n",
    "        # Model does not exist, create a new one\n",
    "        model_resource_name = None\n",
    "        print(f\"Model with display name '{model_display_name}' does not exist. Creating a new model.\")\n",
    "        model_version = \"v1\"\n",
    "\n",
    "    # Upload the model\n",
    "    model = aiplatform.Model.upload(\n",
    "        display_name=model_display_name,\n",
    "        description=model_description,\n",
    "        serving_container_image_uri=docker_image_uri,\n",
    "        serving_container_predict_route=predict_route + app_name,\n",
    "        serving_container_health_route=health_route,\n",
    "        serving_container_ports=serving_container_ports,\n",
    "        parent_model=model_resource_name,  # Register under an existing model if applicable\n",
    "    )\n",
    "\n",
    "    model.wait()\n",
    "\n",
    "    # Return output information\n",
    "    return (model.display_name, model.resource_name, model_version)\n",
    "\n",
    "@dsl.pipeline(\n",
    "    name=\"data-prep-and-train\",\n",
    "    pipeline_root=f\"gs://{BUCKET_NAME}/pipeline_root/\",\n",
    ")\n",
    "def data_prep_and_train_pipeline():\n",
    "    # Step 1: Data Preparation\n",
    "    data_prep_task = data_prep_stage(\n",
    "        code_bucket_path=SOURCE_CODE,\n",
    "        input_path=DATA_PATH,\n",
    "        output_dir=OUTPUT_DIR,\n",
    "    )\n",
    "    \n",
    "    optuna_experiment_task = run_optuna_experiment(\n",
    "        code_bucket_path=SOURCE_CODE,\n",
    "        data_path=DATA_PATH,\n",
    "        train_data=data_prep_task.outputs[\"train_data\"],\n",
    "        val_data=data_prep_task.outputs[\"val_data\"],\n",
    "        test_data=data_prep_task.outputs[\"test_data\"],\n",
    "    ).set_cpu_limit(\"8\") \\\n",
    "     .set_memory_limit(\"32G\") \\\n",
    "     .set_gpu_limit(1) \\\n",
    "     .set_accelerator_type(\"NVIDIA_TESLA_T4\")\n",
    "\n",
    "\n",
    "    # Step 2: Training and Saving Model\n",
    "    train_save_task = train_save_stage(\n",
    "        code_bucket_path=SOURCE_CODE,\n",
    "        data_path=OUTPUT_DIR,\n",
    "        model_save_path=MODEL_SAVE_PATH,\n",
    "        train_data=data_prep_task.outputs[\"train_data\"],\n",
    "        val_data=data_prep_task.outputs[\"val_data\"],\n",
    "        best_hyperparams_metrics=optuna_experiment_task.outputs[\"best_hyperparams_metrics\"],\n",
    "    ).set_cpu_limit(\"8\") \\\n",
    "     .set_memory_limit(\"32G\") \\\n",
    "     .set_gpu_limit(1) \\\n",
    "     .set_accelerator_type(\"NVIDIA_TESLA_T4\")\n",
    "\n",
    "    # Step 3: Model Evaluation\n",
    "    evaluate_task = evaluate_model_component(\n",
    "        code_bucket_path=SOURCE_CODE,\n",
    "        model_gcs_path=train_save_task.outputs[\"model\"],  # Pass Model artifact\n",
    "        test_data=data_prep_task.outputs[\"test_data\"],  # Pass Test Data artifact\n",
    "        f1_threshold=0.6,\n",
    "    )\n",
    "\n",
    "    optuna_experiment_task.after(data_prep_task)\n",
    "    train_save_task.after(optuna_experiment_task)\n",
    "    \n",
    "    # Conditional Logic: Check if eval passed\n",
    "    with dsl.If(evaluate_task.outputs[\"eval_pass\"] == \"true\", name=\"conditional-validation-check\"):\n",
    "        # Step 4: Evaluate Slices\n",
    "        evaluate_slices_task = evaluate_slices_component(\n",
    "            code_bucket_path=SOURCE_CODE,\n",
    "            model_gcs_path=train_save_task.outputs[\"model\"], \n",
    "            test_data=data_prep_task.outputs[\"test_data\"],  \n",
    "            gcs_artifact_path=SLICE_METRIC_PATH,\n",
    "            f1_threshold=0.6,\n",
    "        )\n",
    "        \n",
    "        # Step 5: Bias Detection\n",
    "        bias_detect_task = bias_detect_component(\n",
    "            code_bucket_path=SOURCE_CODE,\n",
    "            metrics=evaluate_slices_task.outputs[\"eval_slices_metrics\"],\n",
    "            gcs_artifact_path=SLICE_METRIC_PATH,\n",
    "        )\n",
    "        evaluate_slices_task.after(evaluate_task)\n",
    "        bias_detect_task.after(evaluate_slices_task)\n",
    "\n",
    "        with dsl.If(bias_detect_task.outputs[\"bias_detect\"] == \"false\", name=\"bias-check-condtional-deploy\"):\n",
    "\n",
    "            # Step 6: Build and Push TorchServe Image\n",
    "            build_and_push_torchserve_image_op = build_and_push_torchserve_image(\n",
    "                code_bucket_path=SOURCE_CODE, \n",
    "                gcp_project=GCP_PROJECT,\n",
    "                gcp_region=GCP_REGION,\n",
    "                bucket_name=BUCKET_NAME,\n",
    "                docker_image_name=\"pytorch_predict_review_sentiment_bert_model\",\n",
    "                model_gcs_path=train_save_task.outputs[\"model\"],\n",
    "            )\n",
    "        # Task dependencies within the successful branch\n",
    "\n",
    "\n",
    "            upload_model_task = upload_model_to_registry(\n",
    "                project_id=PROJECT_ID,\n",
    "                region=GCP_REGION,\n",
    "                bucket_name=BUCKET_NAME,\n",
    "                model_display_name=MODEL_DISPLAY_NAME,\n",
    "                docker_image_uri=CUSTOM_PREDICTOR_IMAGE_URI,\n",
    "                model_description=MODEL_DESCRIPTION,\n",
    "                app_name=APP_NAME,\n",
    "            )\n",
    "            upload_model_task.set_caching_options(False)\n",
    "            build_and_push_torchserve_image_op.after(bias_detect_task)\n",
    "            upload_model_task.after(build_and_push_torchserve_image_op)\n",
    "\n",
    "    # with dsl.If(evaluate_task.outputs[\"eval_pass\"] == \"false\", name=\"conditional-validation-check\"):\n",
    "    #     train_save_task.after(evaluate_task)\n",
    "\n",
    "from kfp.v2.compiler import Compiler\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "# Define the pipeline file path\n",
    "pipeline_file_path = \"data_prep_and_train_pipeline.json\"\n",
    "\n",
    "# Compile the pipeline\n",
    "Compiler().compile(pipeline_func=data_prep_and_train_pipeline, package_path=pipeline_file_path)\n",
    "\n",
    "# Initialize Vertex AI\n",
    "aiplatform.init(project=GCP_PROJECT, location=GCP_REGION)\n",
    "\n",
    "# Submit the pipeline to Vertex AI\n",
    "pipeline_job = aiplatform.PipelineJob(\n",
    "    display_name=\"data-prep-and-train-pipeline\",\n",
    "    template_path=pipeline_file_path,\n",
    "    pipeline_root=f\"gs://{BUCKET_NAME}/pipeline_root/\",\n",
    ")\n",
    "\n",
    "pipeline_job.submit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUSTOM_PREDICTOR_IMAGE_URI = gcr.io/amazonreviewssentimentanalysis/pytorch_predict_review_sentiment_bert_model\n"
     ]
    }
   ],
   "source": [
    "CUSTOM_PREDICTOR_IMAGE_URI = f\"gcr.io/{PROJECT_ID}/pytorch_predict_{APP_NAME}\"\n",
    "print(f\"CUSTOM_PREDICTOR_IMAGE_URI = {CUSTOM_PREDICTOR_IMAGE_URI}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Building 0.0s (0/1)                                    docker:desktop-linux\n",
      "\u001b[?25h\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.2s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.2s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.3s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.3s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.5s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.4s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.6s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.6s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.8s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.7s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.9s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   0.9s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.1s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   1.1s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.2s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   1.2s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.4s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   1.3s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.5s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   1.5s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.7s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   1.7s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.8s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   1.8s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.0s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   1.9s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.1s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   2.1s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.3s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   2.3s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.4s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   2.4s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.6s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   2.5s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.7s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   2.7s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.9s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   2.9s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 3.0s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   3.0s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 3.2s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   3.1s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 3.3s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   3.3s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 3.5s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   3.5s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 3.6s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   3.6s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 3.8s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   3.7s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 3.9s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   3.9s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 4.1s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   4.0s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 4.2s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   4.2s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 4.4s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   4.4s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 4.5s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   4.5s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 4.7s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   4.6s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 4.8s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   4.8s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 5.0s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   5.0s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 5.1s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   5.1s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 5.3s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   5.2s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 5.4s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   5.4s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 5.6s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   5.6s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 5.7s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   5.7s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 5.9s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   5.8s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 6.0s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   6.0s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 6.2s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   6.2s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 6.3s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   6.3s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 6.5s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   6.4s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 6.6s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   6.6s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 6.8s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   6.8s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 6.9s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   6.9s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 7.1s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   7.0s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 7.2s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   7.2s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 7.4s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   7.3s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 7.5s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   7.5s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 7.7s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   7.7s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 7.8s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   7.8s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 8.0s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   7.9s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 8.1s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   8.1s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 8.3s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   8.3s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 8.4s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   8.4s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 8.6s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   8.5s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 8.7s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   8.7s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 8.9s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   8.8s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 9.0s (1/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.0s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 9.1s (2/2)                                    docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 9.2s (13/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 9.4s (14/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[2m => => # -rw-rw-r-- 1 root         root  309 Sep 30 21:38 config.properties    \n",
      "\u001b[0m\u001b[2m => => # -rw-rw-r-- 1 root         root 6602 Dec  2 14:49 custom_handler.py    \n",
      "\u001b[0m\u001b[2m => => # -rw-rw-r-- 1 root         root   66 Nov 30 20:07 index_to_name.json   \n",
      "\u001b[0m\u001b[2m => => # drwxr-xr-x 2 model-server root 4096 Sep 30 21:41 model-store          \n",
      "\u001b[0m\u001b[2m => => # drwxr-xr-x 1 model-server root 4096 Nov 25 17:35 tmp                  \n",
      "\u001b[0m\u001b[2m => => # drwxr-xr-x 3 root         root 4096 Nov 29 20:05 utils                \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 9.5s (16/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m                                                                                \n",
      "                                                                                \n",
      "                                                                                \n",
      "\u001b[3A\u001b[0G\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 9.7s (16/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 9.7s (17/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 9.8s (18/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 9.9s (19/21)                                  docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 10.1s (19/21)                                 docker:desktop-linux\n",
      "\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m => [16/17] RUN chown -R model-server:model-server /home/model-server      0.2s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 10.2s (19/21)                                 docker:desktop-linux\n",
      "\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m => [16/17] RUN chown -R model-server:model-server /home/model-server      0.3s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 10.4s (19/21)                                 docker:desktop-linux\n",
      "\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m => [16/17] RUN chown -R model-server:model-server /home/model-server      0.5s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 10.5s (19/21)                                 docker:desktop-linux\n",
      "\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m => [16/17] RUN chown -R model-server:model-server /home/model-server      0.6s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 10.7s (19/21)                                 docker:desktop-linux\n",
      "\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m => [16/17] RUN chown -R model-server:model-server /home/model-server      0.8s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 10.8s (19/21)                                 docker:desktop-linux\n",
      "\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m => [16/17] RUN chown -R model-server:model-server /home/model-server      0.9s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 11.0s (19/21)                                 docker:desktop-linux\n",
      "\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.1s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 11.1s (19/21)                                 docker:desktop-linux\n",
      "\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.2s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 11.3s (19/21)                                 docker:desktop-linux\n",
      "\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.4s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 11.4s (19/21)                                 docker:desktop-linux\n",
      "\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.5s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 11.6s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 11.7s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  0.2s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 11.9s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  0.3s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 12.0s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  0.5s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 12.2s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  0.6s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 12.3s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  0.8s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 12.5s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  0.9s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 12.6s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  1.1s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 12.8s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  1.2s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 12.9s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  1.4s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 13.1s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  1.5s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 13.2s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  1.7s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 13.4s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  1.8s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 13.5s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  2.0s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 13.7s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  2.1s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 13.8s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  2.3s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 14.0s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  2.4s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 14.1s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  2.6s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 14.3s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  2.7s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 14.4s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  2.9s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 14.6s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  3.0s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 14.7s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  3.2s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 14.9s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  3.3s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 15.0s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  3.5s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 15.2s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  3.6s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 15.3s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  3.8s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 15.5s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  3.9s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 15.6s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  4.1s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 15.8s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  4.2s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 15.9s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  4.4s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 16.1s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  4.5s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 16.2s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  4.7s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 16.4s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  4.8s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 16.5s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  5.0s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 16.7s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  5.1s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 16.8s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  5.3s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 17.0s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  5.4s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 17.1s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  5.6s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 17.3s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  5.7s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 17.4s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  5.9s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 17.6s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  6.0s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 17.7s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  6.2s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 17.9s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  6.3s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 18.0s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  6.5s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 18.2s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  6.6s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 18.3s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  6.8s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 18.5s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  6.9s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 18.6s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  7.1s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 18.8s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  7.2s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 18.9s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  7.4s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 19.1s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  7.5s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 19.2s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  7.7s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 19.4s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  7.8s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 19.5s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  8.0s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 19.7s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  8.1s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 19.8s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  8.3s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 20.0s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  8.4s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 20.1s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  8.6s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 20.3s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  8.7s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 20.4s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  8.9s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 20.6s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  9.0s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 20.7s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  9.2s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 20.9s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  9.3s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 21.0s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  9.5s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 21.2s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  9.6s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 21.3s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  9.8s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 21.5s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentiment  9.9s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 21.6s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  10.1s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 21.8s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  10.2s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 21.9s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  10.4s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 22.1s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  10.5s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 22.2s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  10.7s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 22.4s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  10.8s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 22.5s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  11.0s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 22.7s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  11.1s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 22.8s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  11.3s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 23.0s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  11.4s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 23.1s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  11.6s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 23.3s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  11.7s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 23.4s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  11.9s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 23.6s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  12.0s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 23.7s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  12.2s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 23.9s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  12.3s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 24.0s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  12.5s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 24.2s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  12.6s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 24.3s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  12.8s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 24.5s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  12.9s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 24.6s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  13.1s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 24.8s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  13.2s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 24.9s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  13.4s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 25.1s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  13.5s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 25.2s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  13.7s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 25.4s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  13.8s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 25.5s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  14.0s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 25.7s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  14.1s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 25.8s (20/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  14.3s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 25.9s (21/21)                                 docker:desktop-linux\n",
      "\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m\u001b[34m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  14.3s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 26.0s (21/22)                                 docker:desktop-linux\n",
      "\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m\u001b[34m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  14.3s\n",
      "\u001b[0m => exporting to image                                                     0.1s\n",
      " => => exporting layers                                                    0.1s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 26.2s (21/22)                                 docker:desktop-linux\n",
      "\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m\u001b[34m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  14.3s\n",
      "\u001b[0m => exporting to image                                                     0.3s\n",
      " => => exporting layers                                                    0.3s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 26.3s (21/22)                                 docker:desktop-linux\n",
      "\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m\u001b[34m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  14.3s\n",
      "\u001b[0m => exporting to image                                                     0.4s\n",
      " => => exporting layers                                                    0.4s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 26.4s (21/22)                                 docker:desktop-linux\n",
      "\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m\u001b[34m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  14.3s\n",
      "\u001b[0m => exporting to image                                                     0.6s\n",
      "\u001b[34m => => exporting layers                                                    0.6s\n",
      "\u001b[0m => => writing image sha256:2223e1e335d701bd75caeb5327bb0351561081daf6245  0.0s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 26.5s (22/22) FINISHED                        docker:desktop-linux\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 2.33kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/pytorch/torchserve:latest-cpu   9.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/17] FROM docker.io/pytorch/torchserve:latest-cpu@sha256:50e189492  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 14.48kB                                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/17] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/17] RUN pip3 install transformers                           0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/17] RUN ls -l                                               0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/17] WORKDIR /home/model-server/                             0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/17] COPY ./bert-sent-model /home/model-server/bert-sent-mo  0.0s\n",
      "\u001b[0m\u001b[34m => [ 7/17] COPY ./custom_handler.py /home/model-server/custom_handler.py  0.0s\n",
      "\u001b[0m\u001b[34m => [ 8/17] COPY ./bert_model_torch_serve.py /home/model-server/bert_mode  0.0s\n",
      "\u001b[0m\u001b[34m => [ 9/17] COPY ./utils /home/model-server/utils/                         0.0s\n",
      "\u001b[0m\u001b[34m => [10/17] COPY ./index_to_name.json /home/model-server/                  0.0s\n",
      "\u001b[0m\u001b[34m => [11/17] RUN ls -l /home/model-server                                   0.1s\n",
      "\u001b[0m\u001b[34m => [12/17] RUN printf \"\\nservice_envelope=json\" >> /home/model-server/co  0.1s\n",
      "\u001b[0m\u001b[34m => [13/17] RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home  0.2s\n",
      "\u001b[0m\u001b[34m => [14/17] RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /hom  0.1s\n",
      "\u001b[0m\u001b[34m => [15/17] RUN printf \"\\ndisable_token_authorization=true\" >> /home/mode  0.1s\n",
      "\u001b[0m\u001b[34m => [16/17] RUN chown -R model-server:model-server /home/model-server      1.6s\n",
      "\u001b[0m\u001b[34m => [17/17] RUN torch-model-archiver -f     --model-name=review_sentimen  14.3s\n",
      "\u001b[0m\u001b[34m => exporting to image                                                     0.6s\n",
      "\u001b[0m\u001b[34m => => exporting layers                                                    0.6s\n",
      "\u001b[0m\u001b[34m => => writing image sha256:2223e1e335d701bd75caeb5327bb0351561081daf6245  0.0s\n",
      "\u001b[0m\u001b[34m => => naming to gcr.io/amazonreviewssentimentanalysis/pytorch_predict_re  0.0s\n",
      "\u001b[0m\u001b[?25h\n",
      "View build details: \u001b]8;;docker-desktop://dashboard/build/desktop-linux/desktop-linux/hixmblw38cqvtkils3l9ftobc\u001b\\docker-desktop://dashboard/build/desktop-linux/desktop-linux/hixmblw38cqvtkils3l9ftobc\u001b]8;;\u001b\\\n",
      "\u001b[1m\n",
      "What's next:\u001b[0m\n",
      "    View a summary of image vulnerabilities and recommendations  \u001b[36mdocker scout quickview \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!docker build \\\n",
    "  --tag=$CUSTOM_PREDICTOR_IMAGE_URI \\\n",
    "  ./src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error response from daemon: No such container: local_bert_classifier\n",
      "8ded1bf35bc23612036cef02486de407cb3e11eab1c78483a8674254999132a6\n"
     ]
    }
   ],
   "source": [
    "!docker stop local_bert_classifier\n",
    "!docker run -t -d --rm -p 7080:7080 --name=local_bert_classifier $CUSTOM_PREDICTOR_IMAGE_URI\n",
    "# !sleep 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./pipeline_utils.py\n"
     ]
    }
   ],
   "source": [
    "# %%writefile ./pipeline_utils.py\n",
    "# def download_files_from_gcs(code_bucket_path: str, code_dir: str, allowed_extensions=None):\n",
    "#     \"\"\"\n",
    "#     Downloads files from a GCS bucket and saves them to a specified local directory.\n",
    "\n",
    "#     Args:\n",
    "#         code_bucket_path (str): The GCS bucket path (e.g., gs://bucket-name/folder).\n",
    "#         code_dir (str): The local directory where files will be downloaded.\n",
    "#         allowed_extensions (set): A set of allowed file extensions to filter downloads.\n",
    "\n",
    "#     Returns:\n",
    "#         None\n",
    "#     \"\"\"\n",
    "#     import os\n",
    "#     import logging\n",
    "#     from google.cloud import storage\n",
    "\n",
    "#     # Configure logging\n",
    "#     logging.basicConfig(level=logging.INFO)\n",
    "#     logger = logging.getLogger(__name__)\n",
    "\n",
    "#     # Parse bucket name and prefix from the GCS path\n",
    "#     bucket_name = code_bucket_path.split('/')[2]\n",
    "#     prefix = '/'.join(code_bucket_path.split('/')[3:])\n",
    "\n",
    "#     # Initialize the GCS client\n",
    "#     client = storage.Client()\n",
    "#     bucket = client.bucket(bucket_name)\n",
    "#     blobs = client.list_blobs(bucket, prefix=prefix)\n",
    "\n",
    "#     # Create the target directory\n",
    "#     os.makedirs(code_dir, exist_ok=True)\n",
    "\n",
    "#     # Set default allowed extensions\n",
    "#     if allowed_extensions is None:\n",
    "#         allowed_extensions = {\".py\", \".json\", \".yaml\", \".csv\", \".pkl\"}\n",
    "\n",
    "#     # Download files\n",
    "#     for blob in blobs:\n",
    "#         if any(blob.name.endswith(ext) for ext in allowed_extensions):\n",
    "#             relative_path = blob.name[len(prefix):].lstrip(\"/\")\n",
    "#             file_path = os.path.join(code_dir, relative_path)\n",
    "#             os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "#             blob.download_to_filename(file_path)\n",
    "#             logger.info(f\"Downloaded {blob.name} to {file_path}\")\n",
    "\n",
    "#     logger.info(f\"All files downloaded to {code_dir}\")\n",
    "\n",
    "# def load_module_from_file(file_path):\n",
    "#     module_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "#     spec = importlib.util.spec_from_file_location(module_name, file_path)\n",
    "#     module = importlib.util.module_from_spec(spec)\n",
    "#     spec.loader.exec_module(module)\n",
    "#     return module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import kfp\n",
    "# from kfp.v2.dsl import pipeline, component\n",
    "# from kfp.v2 import compiler\n",
    "# from google.cloud import storage\n",
    "# import os\n",
    "\n",
    "# # Define the pipeline component\n",
    "# @component(base_image=\"python:3.9\", packages_to_install=[\"google-cloud-storage\"])\n",
    "# def gcs_transfer_component(\n",
    "#     source_bucket: str, destination_bucket: str, file_path_source: str, file_path_dest: str\n",
    "# ):\n",
    "#     \"\"\"Component to transfer files between GCS buckets.\"\"\"\n",
    "#     from google.cloud import storage  # Import inside component to avoid issues\n",
    "#     import os\n",
    "#     # Initialize GCS client\n",
    "#     storage_client = storage.Client()\n",
    "\n",
    "#     # Download the file from the source bucket\n",
    "#     source_blob = storage_client.bucket(source_bucket).blob(file_path_source)\n",
    "#     local_file = f\"/tmp/{os.path.basename(file_path_source)}\"\n",
    "#     source_blob.download_to_filename(local_file)\n",
    "#     print(f\"Downloaded {file_path_source} from bucket {source_bucket} to {local_file}\")\n",
    "\n",
    "#     # Upload the file to the destination bucket\n",
    "#     dest_blob = storage_client.bucket(destination_bucket).blob(f\"{file_path_dest}/{os.path.basename(file_path_source)}\")\n",
    "#     dest_blob.upload_from_filename(local_file)\n",
    "#     print(f\"Uploaded {file_path_source} to {destination_bucket}/{file_path_dest}\")\n",
    "\n",
    "# # Define the pipeline\n",
    "# @pipeline(name=\"gcs-transfer-pipeline\")\n",
    "# def gcs_pipeline(\n",
    "#     source_bucket: str = \"arsa_model_deployment_uscentral\",\n",
    "#     destination_bucket: str = \"arsa_model_deployment_uscentral_v2\",\n",
    "#     file_path_source: str = \"code/predictor/bert-sent-model/final_model.pth\",\n",
    "#     file_path_dest: str = \"output/models\",\n",
    "# ):\n",
    "#     # Add the GCS transfer component to the pipeline\n",
    "#     gcs_transfer_component(\n",
    "#         source_bucket=source_bucket,\n",
    "#         destination_bucket=destination_bucket,\n",
    "#         file_path_source=file_path_source,\n",
    "#         file_path_dest=file_path_dest,\n",
    "#     )\n",
    "\n",
    "# # Compile and run the pipeline from a notebook\n",
    "# from google.cloud import aiplatform\n",
    "\n",
    "# # Set GCP and Vertex AI configuration\n",
    "# PROJECT_ID = \"amazonreviewssentimentanalysis\"\n",
    "# REGION = \"us-central1\"\n",
    "# PIPELINE_NAME = \"gcs-transfer-pipeline\"\n",
    "# STAGING_BUCKET = \"gs://arsa_model_deployment_uscentral\"  # Fully qualified GCS bucket URI\n",
    "\n",
    "# # Compile the pipeline\n",
    "# pipeline_json = f\"{PIPELINE_NAME}.json\"\n",
    "# compiler.Compiler().compile(\n",
    "#     pipeline_func=gcs_pipeline,\n",
    "#     package_path=pipeline_json,\n",
    "# )\n",
    "\n",
    "# # Initialize the Vertex AI client\n",
    "# aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=STAGING_BUCKET)\n",
    "\n",
    "# # Submit the pipeline job\n",
    "# pipeline_job = aiplatform.PipelineJob(\n",
    "#     display_name=PIPELINE_NAME,\n",
    "#     template_path=pipeline_json,\n",
    "#     parameter_values={\n",
    "#         \"source_bucket\": \"arsa_model_deployment_uscentral\",\n",
    "#         \"destination_bucket\": \"arsa_model_deployment_uscentral_v2\",\n",
    "#         \"file_path_source\": \"code/predictor/bert-sent-model/final_model.pth\",\n",
    "#         \"file_path_dest\": \"output/models\",\n",
    "#     },\n",
    "# )\n",
    "\n",
    "# # Run the pipeline\n",
    "# pipeline_job.submit()\n",
    "\n",
    "# print(f\"Pipeline {PIPELINE_NAME} has been submitted.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Old pipeline\n",
    "\n",
    "# @dsl.pipeline(\n",
    "#     name=\"data-prep-and-train\",\n",
    "#     pipeline_root=f\"gs://{BUCKET_NAME}/pipeline_root/\",\n",
    "# )\n",
    "# def data_prep_and_train_pipeline():\n",
    "#     # Step 1: Data Preparation\n",
    "#     data_prep_task = data_prep_stage(\n",
    "#         code_bucket_path=SOURCE_CODE,\n",
    "#         input_path=DATA_PATH,\n",
    "#         output_dir=OUTPUT_DIR,\n",
    "#     )\n",
    "\n",
    "#     # Step 2: Training and Saving Model\n",
    "#     train_save_task = train_save_stage(\n",
    "#         code_bucket_path=SOURCE_CODE,\n",
    "#         data_path=OUTPUT_DIR,\n",
    "#         model_save_path=MODEL_SAVE_PATH,\n",
    "#         train_data=data_prep_task.outputs[\"train_data\"],\n",
    "#         val_data=data_prep_task.outputs[\"val_data\"],\n",
    "\n",
    "#     ).set_cpu_limit(\"8\") \\\n",
    "#      .set_memory_limit(\"32G\") \\\n",
    "#      .set_gpu_limit(1) \\\n",
    "#      .set_accelerator_type(\"NVIDIA_TESLA_T4\")\n",
    "\n",
    "#     evaluate_task = evaluate_model_component(\n",
    "#         code_bucket_path=SOURCE_CODE,\n",
    "#         model_gcs_path=train_save_task.outputs[\"model\"],  # Pass Model artifact\n",
    "#         test_data=data_prep_task.outputs[\"test_data\"],  # Pass Test Data artifact\n",
    "#         f1_threshold=0.6,\n",
    "#     )\n",
    "    \n",
    "    # evaluate_slices_task = evaluate_slices_component(\n",
    "    #     code_bucket_path=SOURCE_CODE,\n",
    "    #     model_gcs_path=train_save_task.outputs[\"model\"], \n",
    "    #     test_data=data_prep_task.outputs[\"test_data\"],  \n",
    "    #     gcs_artifact_path = SLICE_METRIC_PATH,\n",
    "    #     f1_threshold=0.6,\n",
    "    # )\n",
    "    # bias_detect_task = bias_detect_component(\n",
    "    #     code_bucket_path=SOURCE_CODE,\n",
    "    #     metrics=evaluate_slices_task.outputs[\"eval_slices_metrics\"],\n",
    "    #     gcs_artifact_path = SLICE_METRIC_PATH,\n",
    "    # )\n",
    "\n",
    "    # build_and_push_torchserve_image_op = build_and_push_torchserve_image(\n",
    "    #         code_bucket_path=SOURCE_CODE, \n",
    "    #         gcp_project=GCP_PROJECT,\n",
    "    #         gcp_region=GCP_REGION,\n",
    "    #         bucket_name=BUCKET_NAME,\n",
    "    #         docker_image_name=\"pytorch_predict_review_sentiment_bert_model\",\n",
    "    #         model_gcs_path=train_save_task.outputs[\"model\"],\n",
    "    #     )\n",
    "    \n",
    "    # train_save_task.after(data_prep_task)\n",
    "    # evaluate_task.after(train_save_task)\n",
    "\n",
    "    # evaluate_slices_task.after(evaluate_task)  \n",
    "    # bias_detect_task.after(evaluate_slices_task)\n",
    "    # build_and_push_torchserve_image_op.after(bias_detect_task)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops_pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
